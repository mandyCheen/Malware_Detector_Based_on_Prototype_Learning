{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all datasets...\n",
      "train dataset shape: (560, 14)\n",
      "train dataset family number: 28\n",
      "test dataset shape: (260, 14)\n",
      "test dataset family number: 13\n",
      "Vectorizing byte sequence using TF-IDF.\n"
     ]
    }
   ],
   "source": [
    "from malwareDetector import malwareDetector\n",
    "from dataLoader import DatasetLoad\n",
    "from byteSequenceVectorize import ByteSequenceVectorizer\n",
    "\n",
    "detector = malwareDetector(cluster=False, train=True, val=False, cpuArch=\"x86_64\",\n",
    "                            support_shots=5, query_shots=5, class_per_iter=None, class_per_iter_test=5,\n",
    "                            loss=\"\", dropout_prob=0.5)\n",
    "\n",
    "dataset = DatasetLoad(detector)\n",
    "\n",
    "vectorize = ByteSequenceVectorizer(method = \"tfidf\", detector = detector, dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorize Method:  tfidf\n",
      "Loading vectorized byte sequence from ./embedding...\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorize Method: \", vectorize.vectorize_method)\n",
    "featureDim = 1000\n",
    "n_gramRange = (2, 4)\n",
    "\n",
    "train_X, test_X, val_X, train_y, test_y, val_y, train_map, test_map, val_map = vectorize.vectorize_func(featureDim, n_gramRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape:  (560, 1000) <class 'numpy.ndarray'>\n",
      "Train y shape:  (560,) <class 'numpy.ndarray'>\n",
      "Test X shape:  (260, 1000)\n",
      "Test y shape:  (260,)\n",
      "Train Map:  {0: 'aenjaris', 1: 'blueshell', 2: 'bpfdoor', 3: 'cleanlog', 4: 'cobaltstrike', 5: 'cryptonote', 6: 'dnscat', 7: 'drtycow', 8: 'exploitscan', 9: 'ezuriloader', 10: 'fscan', 11: 'gafgyt', 12: 'hive', 13: 'horsepill', 14: 'lady', 15: 'malsource', 16: 'malxmr', 17: 'meterpreter', 18: 'poseidon', 19: 'psybnc', 20: 'rekoobe', 21: 'reversessh', 22: 'revproxy', 23: 'sliver', 24: 'stowaway', 25: 'vtflooder', 26: 'winexe', 27: 'xmrig'}\n",
      "Test Map:  {0: 'camelot', 1: 'chisel', 2: 'dnsamp', 3: 'dropperl', 4: 'fritzfrog', 5: 'kaiji', 6: 'merlin', 7: 'mirai', 8: 'pnscan', 9: 'prochider', 10: 'sshdoor', 11: 'tsunami', 12: 'winnti'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train X shape: \", train_X.shape, type(train_X))\n",
    "print(\"Train y shape: \", train_y.shape, type(train_y))\n",
    "print(\"Test X shape: \", test_X.shape)\n",
    "print(\"Test y shape: \", test_y.shape)\n",
    "if(val_X is not None):\n",
    "    print(\"Val X shape: \", val_X.shape)\n",
    "    print(\"Val y shape: \", val_y.shape)\n",
    "print(\"Train Map: \", train_map)\n",
    "print(\"Test Map: \", test_map)\n",
    "if(val_map is not None):\n",
    "    print(\"Val Map: \", val_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes per iteration: 28\n",
      "N-shot: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mandy900619/Tools/Anaconda/envs/byteSequence/lib/python3.11/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 0 ===\n",
      "Avg Train Loss: 2.9372976064682006, Avg Train Acc: 0.2695000039041042 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 1 ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detector\u001b[38;5;241m.\u001b[39mtrain:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_Y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/experiment/byteSequence/MalwareDetectorBasedOnPrototypeLearning/malwareDetector.py:136\u001b[0m, in \u001b[0;36mmalwareDetector.trainModel\u001b[0;34m(self, train_X, train_Y, val_X, val_Y, save_model, new_label_mapping)\u001b[0m\n\u001b[1;32m    127\u001b[0m loss, acc, proto, protoID, _, _, _\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlossFunc(embeddings, target\u001b[38;5;241m=\u001b[39mlabels, n_support\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_shots)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# if self.cluster and valLoader is not None:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m#     for i in range(proto.shape[0]):\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#         if prototypesCounts.get(protoID[i].item()) is None:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#             prototypesCounts[protoID[i].item()] += 1\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m#             prototypes[protoID[i].item()] += proto[i]\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()   \n\u001b[1;32m    138\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/Tools/Anaconda/envs/byteSequence/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Tools/Anaconda/envs/byteSequence/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Tools/Anaconda/envs/byteSequence/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if detector.train:\n",
    "    detector.trainModel(train_X=train_X, train_Y = train_y, val_X=val_X, val_Y=val_y, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.7490400008559227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7490400008559227"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.testModel(test_X=test_X, test_Y=test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byteSequence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
