{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all datasets...\n",
      "train dataset shape: (560, 14)\n",
      "train dataset family number: 28\n",
      "test dataset shape: (260, 14)\n",
      "test dataset family number: 13\n",
      "Vectorizing byte sequence using TF-IDF.\n"
     ]
    }
   ],
   "source": [
    "from malwareDetector import malwareDetector\n",
    "from dataLoader import DatasetLoad\n",
    "from byteSequenceVectorize import ByteSequenceVectorizer\n",
    "\n",
    "detector = malwareDetector(cluster=False, train=True, val=False, cpuArch=\"x86_64\",\n",
    "                            support_shots=5, query_shots=5, class_per_iter=None, class_per_iter_test=5,\n",
    "                            loss=\"\", dropout_prob=0.5, cuda=True)\n",
    "\n",
    "dataset = DatasetLoad(detector)\n",
    "\n",
    "vectorize = ByteSequenceVectorizer(method = \"tfidf\", detector = detector, dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             file_name  \\\n",
      "0    2c474c5742a1e860ee20d7674e082051b933aa7a98536f...   \n",
      "1    3934b3da6bad0b4a28483e25e7bab919d7ed31f2f51cca...   \n",
      "2    60048c9e66f0cf2a0fd5d53a1a83038c671647f3e42736...   \n",
      "3    6891ccff8e2a1c8fcbc89d7e34b7ce715b22df23ab4a15...   \n",
      "4    a5fbf139f6602f008346d2dadd9cb5ad242e941cd1a7d1...   \n",
      "..                                                 ...   \n",
      "815  99579775cefac5debc75116459d8af5eb5fb9356bea3c6...   \n",
      "816  98bb4792e31c1d523760698c9baf5562eebd56357da5b0...   \n",
      "817  d7ff0db4ae20fce2a754f04c5887880b880fecfeb219ed...   \n",
      "818  3966a30a18b353b0419a4f05a6a25f8ee5efe5890af3ba...   \n",
      "819  29f1c20016301c5d5f46cdcde36cc9e5a060fbc616279c...   \n",
      "\n",
      "                                  md5    label                            CPU  \\\n",
      "0    ed2d62cbc76696f8c7168763bf14e470  Malware  Advanced Micro Devices X86-64   \n",
      "1    e79984ea02b2049b1e74452013529da5  Malware  Advanced Micro Devices X86-64   \n",
      "2    d689feaf9bcbfcf5cd24e650243f949b  Malware  Advanced Micro Devices X86-64   \n",
      "3    d95dd99b3228b31ed17f9b467b9381c4  Malware  Advanced Micro Devices X86-64   \n",
      "4    17437da191cdd75595c5280823b3b1cd  Malware  Advanced Micro Devices X86-64   \n",
      "..                                ...      ...                            ...   \n",
      "815  7e9f438833d029026956205bde5456ad  Malware  Advanced Micro Devices X86-64   \n",
      "816  ce70a40c4400eb6674ff6dd56b7f0035  Malware  Advanced Micro Devices X86-64   \n",
      "817  4dfb6116e5200c10335717d647016d03  Malware  Advanced Micro Devices X86-64   \n",
      "818  a3dfe1480392138598d505456d814e94  Malware  Advanced Micro Devices X86-64   \n",
      "819  207a76b120c5f457f23a35913ceaf0b3  Malware  Advanced Micro Devices X86-64   \n",
      "\n",
      "       family           first_seen        size  is_packed  packer_info  \\\n",
      "0    aenjaris  2024-01-25 10:10:50     66152.0      False          NaN   \n",
      "1    aenjaris  2023-09-26 08:06:25     70816.0      False          NaN   \n",
      "2    aenjaris  2022-08-31 20:48:37     37512.0      False          NaN   \n",
      "3    aenjaris  2023-05-10 08:55:16     74008.0      False          NaN   \n",
      "4    aenjaris  2023-06-15 21:37:16     82040.0      False          NaN   \n",
      "..        ...                  ...         ...        ...          ...   \n",
      "815     xmrig  2024-01-10 19:28:27  12452964.0      False          NaN   \n",
      "816     xmrig  2023-04-07 12:30:14   5785008.0      False          NaN   \n",
      "817     xmrig  2018-08-15 22:07:30   1807426.0      False          NaN   \n",
      "818     xmrig  2023-07-12 10:56:06   5728008.0      False          NaN   \n",
      "819     xmrig  2023-10-14 14:07:21   6024232.0      False          NaN   \n",
      "\n",
      "     packing_algorithm  UPX(3.94)  UPX(3.95)  UPX(4.02)  \\\n",
      "0                  NaN       True       True       True   \n",
      "1                  NaN       True       True       True   \n",
      "2                  NaN       True       True       True   \n",
      "3                  NaN       True       True       True   \n",
      "4                  NaN       True       True       True   \n",
      "..                 ...        ...        ...        ...   \n",
      "815                NaN       True       True       True   \n",
      "816                NaN       True       True       True   \n",
      "817                NaN       True       True       True   \n",
      "818                NaN       True       True       True   \n",
      "819                NaN       True       True       True   \n",
      "\n",
      "                                         byte_sequence  \n",
      "0    31 ed 49 89 d1 5e 48 89 e2 48 83 e4 f0 50 54 4...  \n",
      "1    31 ed 49 89 d1 5e 48 89 e2 48 83 e4 f0 50 54 4...  \n",
      "2    31 ed 49 89 d1 5e 48 89 e2 48 83 e4 f0 50 54 4...  \n",
      "3    f3 0f 1e fa 31 ed 49 89 d1 5e 48 89 e2 48 83 e...  \n",
      "4    31 ed 49 89 d1 5e 48 89 e2 48 83 e4 f0 50 54 4...  \n",
      "..                                                 ...  \n",
      "815  31 ed 49 89 d1 5e 48 89 e2 48 83 e4 f0 50 54 4...  \n",
      "816  31 ed 49 89 d1 5e 48 89 e2 48 83 e4 f0 50 54 4...  \n",
      "817  31 ed 49 89 d1 5e 48 89 e2 48 83 e4 f0 50 54 4...  \n",
      "818  31 ed 49 89 d1 5e 48 89 e2 48 83 e4 f0 50 54 4...  \n",
      "819  f3 0f 1e fa 31 ed 49 89 d1 5e 48 89 e2 48 83 e...  \n",
      "\n",
      "[820 rows x 14 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorize Method:  tfidf\n",
      "Loading vectorized byte sequence from ./embedding...\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorize Method: \", vectorize.vectorize_method)\n",
    "featureDim = 1000\n",
    "n_gramRange = (2, 4)\n",
    "\n",
    "train_X, test_X, val_X, train_y, test_y, val_y, train_map, test_map, val_map = vectorize.vectorize_func(featureDim, n_gramRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape:  (560, 1000) <class 'numpy.ndarray'>\n",
      "Train y shape:  (560,) <class 'numpy.ndarray'>\n",
      "Test X shape:  (260, 1000)\n",
      "Test y shape:  (260,)\n",
      "Train Map:  {0: 'aenjaris', 1: 'blueshell', 2: 'bpfdoor', 3: 'cleanlog', 4: 'cobaltstrike', 5: 'cryptonote', 6: 'dnscat', 7: 'drtycow', 8: 'exploitscan', 9: 'ezuriloader', 10: 'fscan', 11: 'gafgyt', 12: 'hive', 13: 'horsepill', 14: 'lady', 15: 'malsource', 16: 'malxmr', 17: 'meterpreter', 18: 'poseidon', 19: 'psybnc', 20: 'rekoobe', 21: 'reversessh', 22: 'revproxy', 23: 'sliver', 24: 'stowaway', 25: 'vtflooder', 26: 'winexe', 27: 'xmrig'}\n",
      "Test Map:  {0: 'camelot', 1: 'chisel', 2: 'dnsamp', 3: 'dropperl', 4: 'fritzfrog', 5: 'kaiji', 6: 'merlin', 7: 'mirai', 8: 'pnscan', 9: 'prochider', 10: 'sshdoor', 11: 'tsunami', 12: 'winnti'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train X shape: \", train_X.shape, type(train_X))\n",
    "print(\"Train y shape: \", train_y.shape, type(train_y))\n",
    "print(\"Test X shape: \", test_X.shape)\n",
    "print(\"Test y shape: \", test_y.shape)\n",
    "if(val_X is not None):\n",
    "    print(\"Val X shape: \", val_X.shape)\n",
    "    print(\"Val y shape: \", val_y.shape)\n",
    "print(\"Train Map: \", train_map)\n",
    "print(\"Test Map: \", test_map)\n",
    "if(val_map is not None):\n",
    "    print(\"Val Map: \", val_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes per iteration: 28\n",
      "N-shot: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mandy900619/anaconda3/envs/smell/lib/python3.11/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/mandy900619/anaconda3/envs/smell/lib/python3.11/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "=== Epoch: 0 ===\n",
      "Avg Train Loss: 2.691631143093109, Avg Train Acc: 0.2914285735040903 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 1 ===\n",
      "Avg Train Loss: 1.7281360816955567, Avg Train Acc: 0.4381428542733192 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 2 ===\n",
      "Avg Train Loss: 1.3475345146656037, Avg Train Acc: 0.5465000057220459 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 3 ===\n",
      "Avg Train Loss: 1.2208796548843384, Avg Train Acc: 0.5768571448326111 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 4 ===\n",
      "Avg Train Loss: 1.1596046328544616, Avg Train Acc: 0.6002857166528702 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 5 ===\n",
      "Avg Train Loss: 1.1252607649564743, Avg Train Acc: 0.611285714507103 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 6 ===\n",
      "Avg Train Loss: 1.1131408113241195, Avg Train Acc: 0.6193571430444718 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 7 ===\n",
      "Avg Train Loss: 1.099764308333397, Avg Train Acc: 0.6270714288949967 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 8 ===\n",
      "Avg Train Loss: 1.0810418355464935, Avg Train Acc: 0.6275000005960465 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 9 ===\n",
      "Avg Train Loss: 1.072335837483406, Avg Train Acc: 0.6330714291334152 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 10 ===\n",
      "Avg Train Loss: 1.051918595433235, Avg Train Acc: 0.6377142840623855 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 11 ===\n",
      "Avg Train Loss: 1.0402948278188706, Avg Train Acc: 0.6395714271068573 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 12 ===\n",
      "Avg Train Loss: 1.0342830938100815, Avg Train Acc: 0.640642855167389 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 13 ===\n",
      "Avg Train Loss: 1.0233195436000824, Avg Train Acc: 0.6430714285373688 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 14 ===\n",
      "Avg Train Loss: 1.0303961461782456, Avg Train Acc: 0.6439285689592361 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 15 ===\n",
      "Avg Train Loss: 1.0229764157533645, Avg Train Acc: 0.645357141494751 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 16 ===\n",
      "Avg Train Loss: 1.0177147179841994, Avg Train Acc: 0.6453571397066117 (Best: 0.645357141494751)\n",
      "=== Epoch: 17 ===\n",
      "Avg Train Loss: 1.012121085524559, Avg Train Acc: 0.6477142870426178 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 18 ===\n",
      "Avg Train Loss: 1.0152097141742706, Avg Train Acc: 0.6475714284181595 (Best: 0.6477142870426178)\n",
      "=== Epoch: 19 ===\n",
      "Avg Train Loss: 1.0026680839061737, Avg Train Acc: 0.6514285731315613 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 20 ===\n",
      "Avg Train Loss: 0.988127567768097, Avg Train Acc: 0.6532857125997543 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 21 ===\n",
      "Avg Train Loss: 0.9961556392908096, Avg Train Acc: 0.6529999989271164 (Best: 0.6532857125997543)\n",
      "=== Epoch: 22 ===\n",
      "Avg Train Loss: 0.9875092792510987, Avg Train Acc: 0.6544285732507705 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 23 ===\n",
      "Avg Train Loss: 0.9890042638778687, Avg Train Acc: 0.6554999959468841 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 24 ===\n",
      "Avg Train Loss: 0.9943506526947021, Avg Train Acc: 0.6547857135534286 (Best: 0.6554999959468841)\n",
      "=== Epoch: 25 ===\n",
      "Avg Train Loss: 0.9859751403331757, Avg Train Acc: 0.6556428563594818 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 26 ===\n",
      "Avg Train Loss: 0.9869827085733414, Avg Train Acc: 0.655499997138977 (Best: 0.6556428563594818)\n",
      "=== Epoch: 27 ===\n",
      "Avg Train Loss: 0.9856546694040298, Avg Train Acc: 0.6564999991655349 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 28 ===\n",
      "Avg Train Loss: 0.9808832967281341, Avg Train Acc: 0.6564285689592362 (Best: 0.6564999991655349)\n",
      "=== Epoch: 29 ===\n",
      "Avg Train Loss: 0.9753895515203476, Avg Train Acc: 0.6604285675287247 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 30 ===\n",
      "Avg Train Loss: 0.979911880493164, Avg Train Acc: 0.658071426153183 (Best: 0.6604285675287247)\n",
      "=== Epoch: 31 ===\n",
      "Avg Train Loss: 0.9880805420875549, Avg Train Acc: 0.6567142844200134 (Best: 0.6604285675287247)\n",
      "=== Epoch: 32 ===\n",
      "Avg Train Loss: 0.9877554845809936, Avg Train Acc: 0.6578571420907974 (Best: 0.6604285675287247)\n",
      "=== Epoch: 33 ===\n",
      "Avg Train Loss: 0.9848310220241546, Avg Train Acc: 0.6563571399450302 (Best: 0.6604285675287247)\n",
      "=== Epoch: 34 ===\n",
      "Avg Train Loss: 0.9857607388496399, Avg Train Acc: 0.656928573846817 (Best: 0.6604285675287247)\n",
      "=== Epoch: 35 ===\n",
      "Avg Train Loss: 0.9759928476810455, Avg Train Acc: 0.6581428575515748 (Best: 0.6604285675287247)\n",
      "=== Epoch: 36 ===\n",
      "Avg Train Loss: 0.979936797618866, Avg Train Acc: 0.6604999995231629 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 37 ===\n",
      "Avg Train Loss: 0.9820123016834259, Avg Train Acc: 0.6569999974966049 (Best: 0.6604999995231629)\n",
      "=== Epoch: 38 ===\n",
      "Avg Train Loss: 0.9793888968229294, Avg Train Acc: 0.6583571404218673 (Best: 0.6604999995231629)\n",
      "=== Epoch: 39 ===\n",
      "Avg Train Loss: 0.9885423898696899, Avg Train Acc: 0.6560714292526245 (Best: 0.6604999995231629)\n",
      "=== Epoch: 40 ===\n",
      "Avg Train Loss: 0.9823591768741607, Avg Train Acc: 0.6582142823934555 (Best: 0.6604999995231629)\n",
      "=== Epoch: 41 ===\n",
      "Avg Train Loss: 0.9722708261013031, Avg Train Acc: 0.6594999980926514 (Best: 0.6604999995231629)\n",
      "=== Epoch: 42 ===\n",
      "Avg Train Loss: 0.9868627274036408, Avg Train Acc: 0.6569285702705383 (Best: 0.6604999995231629)\n",
      "=== Epoch: 43 ===\n",
      "Avg Train Loss: 0.984389386177063, Avg Train Acc: 0.6572857123613357 (Best: 0.6604999995231629)\n",
      "=== Epoch: 44 ===\n",
      "Avg Train Loss: 0.9803669726848603, Avg Train Acc: 0.6594285690784454 (Best: 0.6604999995231629)\n",
      "=== Epoch: 45 ===\n",
      "Avg Train Loss: 0.9694718611240387, Avg Train Acc: 0.6611428564786911 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 46 ===\n",
      "Avg Train Loss: 0.9841989314556122, Avg Train Acc: 0.657142853140831 (Best: 0.6611428564786911)\n",
      "=== Epoch: 47 ===\n",
      "Avg Train Loss: 0.9823163866996765, Avg Train Acc: 0.6580714303255081 (Best: 0.6611428564786911)\n",
      "=== Epoch: 48 ===\n",
      "Avg Train Loss: 0.9772453355789185, Avg Train Acc: 0.6579999983310699 (Best: 0.6611428564786911)\n",
      "=== Epoch: 49 ===\n",
      "Avg Train Loss: 0.9791252511739731, Avg Train Acc: 0.6587142843008041 (Best: 0.6611428564786911)\n",
      "=== Epoch: 50 ===\n",
      "Avg Train Loss: 0.9793669998645782, Avg Train Acc: 0.6572142845392227 (Best: 0.6611428564786911)\n",
      "=== Epoch: 51 ===\n",
      "Avg Train Loss: 0.9729669845104217, Avg Train Acc: 0.6594285690784454 (Best: 0.6611428564786911)\n",
      "=== Epoch: 52 ===\n",
      "Avg Train Loss: 0.9780130690336227, Avg Train Acc: 0.6584999984502793 (Best: 0.6611428564786911)\n",
      "=== Epoch: 53 ===\n",
      "Avg Train Loss: 0.9742091166973114, Avg Train Acc: 0.6611428564786911 (Best)\n",
      "=== Epoch: 54 ===\n",
      "Avg Train Loss: 0.9750082105398178, Avg Train Acc: 0.658857142329216 (Best: 0.6611428564786911)\n",
      "=== Epoch: 55 ===\n",
      "Avg Train Loss: 0.9823106008768082, Avg Train Acc: 0.6570714247226715 (Best: 0.6611428564786911)\n",
      "=== Epoch: 56 ===\n",
      "Avg Train Loss: 0.9849895238876343, Avg Train Acc: 0.6582142853736878 (Best: 0.6611428564786911)\n",
      "=== Epoch: 57 ===\n",
      "Avg Train Loss: 0.9668350088596344, Avg Train Acc: 0.6598571419715882 (Best: 0.6611428564786911)\n",
      "=== Epoch: 58 ===\n",
      "Avg Train Loss: 0.9783126819133758, Avg Train Acc: 0.6619285696744919 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 59 ===\n",
      "Avg Train Loss: 0.982938112616539, Avg Train Acc: 0.6591428548097611 (Best: 0.6619285696744919)\n",
      "=== Epoch: 60 ===\n",
      "Avg Train Loss: 0.9623195171356201, Avg Train Acc: 0.6622142839431763 (Best)\n",
      "Model saved at ./model/model_x86_64.pt\n",
      "=== Epoch: 61 ===\n",
      "Avg Train Loss: 0.9789718514680863, Avg Train Acc: 0.6590714251995087 (Best: 0.6622142839431763)\n",
      "=== Epoch: 62 ===\n",
      "Avg Train Loss: 0.9759854227304459, Avg Train Acc: 0.6579285717010498 (Best: 0.6622142839431763)\n",
      "=== Epoch: 63 ===\n",
      "Avg Train Loss: 0.973626594543457, Avg Train Acc: 0.6602142834663391 (Best: 0.6622142839431763)\n",
      "=== Epoch: 64 ===\n",
      "Avg Train Loss: 0.9776748949289322, Avg Train Acc: 0.6602142816781997 (Best: 0.6622142839431763)\n",
      "=== Epoch: 65 ===\n",
      "Avg Train Loss: 0.9745909124612808, Avg Train Acc: 0.65928571164608 (Best: 0.6622142839431763)\n",
      "=== Epoch: 66 ===\n",
      "Avg Train Loss: 0.9781940764188767, Avg Train Acc: 0.658714280128479 (Best: 0.6622142839431763)\n",
      "=== Epoch: 67 ===\n",
      "Avg Train Loss: 0.9654084903001785, Avg Train Acc: 0.6617857146263123 (Best: 0.6622142839431763)\n",
      "=== Epoch: 68 ===\n",
      "Avg Train Loss: 0.9771045708656311, Avg Train Acc: 0.6595714282989502 (Best: 0.6622142839431763)\n",
      "=== Epoch: 69 ===\n",
      "Avg Train Loss: 0.98190105676651, Avg Train Acc: 0.6589285725355148 (Best: 0.6622142839431763)\n",
      "=== Epoch: 70 ===\n",
      "Avg Train Loss: 0.9729497820138931, Avg Train Acc: 0.6594285708665848 (Best: 0.6622142839431763)\n",
      "=== Epoch: 71 ===\n",
      "Avg Train Loss: 0.9830135130882263, Avg Train Acc: 0.6589285707473755 (Best: 0.6622142839431763)\n",
      "=== Epoch: 72 ===\n",
      "Avg Train Loss: 0.974757446050644, Avg Train Acc: 0.6597857117652893 (Best: 0.6622142839431763)\n",
      "=== Epoch: 73 ===\n",
      "Avg Train Loss: 0.9732960253953934, Avg Train Acc: 0.659642853140831 (Best: 0.6622142839431763)\n",
      "=== Epoch: 74 ===\n",
      "Avg Train Loss: 0.9738516515493393, Avg Train Acc: 0.660142856836319 (Best: 0.6622142839431763)\n",
      "=== Epoch: 75 ===\n",
      "Avg Train Loss: 0.9757095474004746, Avg Train Acc: 0.6609999984502792 (Best: 0.6622142839431763)\n",
      "=== Epoch: 76 ===\n",
      "Avg Train Loss: 0.9727945446968078, Avg Train Acc: 0.6607142817974091 (Best: 0.6622142839431763)\n",
      "=== Epoch: 77 ===\n",
      "Avg Train Loss: 0.9790996861457825, Avg Train Acc: 0.659928570985794 (Best: 0.6622142839431763)\n",
      "=== Epoch: 78 ===\n",
      "Avg Train Loss: 0.9634721291065216, Avg Train Acc: 0.6619999957084656 (Best: 0.6622142839431763)\n",
      "=== Epoch: 79 ===\n",
      "Avg Train Loss: 0.9803653055429459, Avg Train Acc: 0.6579999965429306 (Best: 0.6622142839431763)\n",
      "=== Epoch: 80 ===\n",
      "Avg Train Loss: 0.9712372809648514, Avg Train Acc: 0.6613571387529373 (Best: 0.6622142839431763)\n",
      "=== Epoch: 81 ===\n",
      "Avg Train Loss: 0.9665491259098054, Avg Train Acc: 0.6604999989271164 (Best: 0.6622142839431763)\n",
      "=== Epoch: 82 ===\n",
      "Avg Train Loss: 0.9798462510108947, Avg Train Acc: 0.6596428555250168 (Best: 0.6622142839431763)\n",
      "=== Epoch: 83 ===\n",
      "Avg Train Loss: 0.9825661808252335, Avg Train Acc: 0.6602857112884521 (Best: 0.6622142839431763)\n",
      "=== Epoch: 84 ===\n",
      "Avg Train Loss: 0.966456349492073, Avg Train Acc: 0.6604999965429306 (Best: 0.6622142839431763)\n",
      "=== Epoch: 85 ===\n",
      "Avg Train Loss: 0.9635458749532699, Avg Train Acc: 0.6616428542137146 (Best: 0.6622142839431763)\n",
      "=== Epoch: 86 ===\n",
      "Avg Train Loss: 0.969213410615921, Avg Train Acc: 0.6605714285373687 (Best: 0.6622142839431763)\n",
      "=== Epoch: 87 ===\n",
      "Avg Train Loss: 0.977631026506424, Avg Train Acc: 0.6601428544521332 (Best: 0.6622142839431763)\n",
      "=== Epoch: 88 ===\n",
      "Avg Train Loss: 0.9730460929870606, Avg Train Acc: 0.6605714285373687 (Best: 0.6622142839431763)\n",
      "=== Epoch: 89 ===\n",
      "Avg Train Loss: 0.9745054531097412, Avg Train Acc: 0.6602857112884521 (Best: 0.6622142839431763)\n",
      "=== Epoch: 90 ===\n",
      "Avg Train Loss: 0.9744176590442657, Avg Train Acc: 0.6596428579092026 (Best: 0.6622142839431763)\n",
      "=== Epoch: 91 ===\n",
      "Avg Train Loss: 0.9706148558855057, Avg Train Acc: 0.6607142853736877 (Best: 0.6622142839431763)\n",
      "=== Epoch: 92 ===\n",
      "Avg Train Loss: 0.9687625890970231, Avg Train Acc: 0.6614285731315612 (Best: 0.6622142839431763)\n",
      "=== Epoch: 93 ===\n",
      "Avg Train Loss: 0.9729178828001023, Avg Train Acc: 0.6612857127189636 (Best: 0.6622142839431763)\n",
      "=== Epoch: 94 ===\n",
      "Avg Train Loss: 0.9707507157325744, Avg Train Acc: 0.6610714244842529 (Best: 0.6622142839431763)\n",
      "=== Epoch: 95 ===\n",
      "Avg Train Loss: 0.9695472937822341, Avg Train Acc: 0.6595714277029038 (Best: 0.6622142839431763)\n",
      "=== Epoch: 96 ===\n",
      "Avg Train Loss: 0.9754750353097915, Avg Train Acc: 0.660071427822113 (Best: 0.6622142839431763)\n",
      "=== Epoch: 97 ===\n",
      "Avg Train Loss: 0.9667497450113296, Avg Train Acc: 0.6608571416139603 (Best: 0.6622142839431763)\n",
      "=== Epoch: 98 ===\n",
      "Avg Train Loss: 0.9737824141979218, Avg Train Acc: 0.6611428534984589 (Best: 0.6622142839431763)\n",
      "=== Epoch: 99 ===\n",
      "Avg Train Loss: 0.977790685892105, Avg Train Acc: 0.659642853140831 (Best: 0.6622142839431763)\n"
     ]
    }
   ],
   "source": [
    "if detector.train:\n",
    "    detector.trainModel(train_X=train_X, train_Y = train_y, val_X=val_X, val_Y=val_y, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.6673333343863487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6673333343863487"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.testModel(test_X=test_X, test_Y=test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byteSequence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
