from malwareDetector import malwareDetector
from typing import Any, Tuple
import os
import pandas as pd
from pandas import DataFrame
from numpy import array
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
import pickle
import warnings

from math import sqrt
from abc import ABCMeta, abstractmethod
import numpy as np
import numpy.linalg as linalg

class byteSequenceVectorize():
    '''
    This class is used to vectorize the byte sequence of malware samples.
    '''
    def __init__(self, length: int = 2000, method: str = "tfidf", detector: malwareDetector = malwareDetector()):
        self.byte_sequence_length = length
        self.vectorize_method = method
        self.detector = detector or malwareDetector()
        self.cpu_arch_list = self._set_cpu_arch_list()

    def _set_cpu_arch_list(self) -> list:
        if self.detector.cpuArch == "crossArch":
            return ["i386", "arm", "x86_64", "mips"]
        return [self.detector.cpuArch]
    
    def load_dataset(self, file_path: str) -> Tuple[DataFrame, DataFrame]:
        '''
        Load the dataset from the dataset path.

        Args:
            file_path: The path to the dataset.
        Returns:
            trainDataset: The training dataset.
            testDataset: The testing dataset.
        '''
        print(f"Loading dataset from {file_path}...")
        try:
            dataset = pd.read_csv(file_path)
        except FileNotFoundError:
            warnings.warn(f"File not found: {file_path}", RuntimeWarning)
            return None, None
        
        try:
            train_dataset = dataset[dataset["train_test"] == "train"]
            test_dataset = dataset[dataset["train_test"] == "test"]
        except KeyError:
            warnings.warn("KeyError: 'train_test' column not found in dataset", RuntimeWarning)
            return None, None
        
        
        print(f"Train dataset shape: {train_dataset.shape}")
        print(f"Test dataset shape: {test_dataset.shape}")

        print("Sorting the dataset by family...")

        try:
            train_dataset = train_dataset.sort_values(by="family", ignore_index=True)
            test_dataset = test_dataset.sort_values(by="family", ignore_index=True)
        except KeyError:
            warnings.warn("KeyError: 'family' column not found. Unable to sort dataset by family.", RuntimeWarning)
            warnings.warn("If the dataset is not sorted by family, the clustering may not work.", RuntimeWarning)

        return train_dataset, test_dataset
    
    def get_vectorize_func(self) -> Any:
        if self.vectorize_method == "tfidf":
            print("Vectorizing byte sequence using TF-IDF.")
            return self.vectorize_tfidf
        else:
            warnings.warn(f"Unsupported vectorize method: {self.vectorize_method}. Defaulting to TF-IDF.", RuntimeWarning)
            return self.vectorize_tfidf

    
    def vectorize_tfidf(self, datasetTrain: DataFrame, datasetTest: DataFrame, 
                        featureDim: int, n_gramRange: tuple, path: str) -> Tuple[array, array, array, array, dict, DataFrame, DataFrame]:
        '''
        Vectorize the byte sequence of malware samples.
        If the vectorized byte sequence exists, load it directly.

        Args:
            datasetTrain: The training dataset. 
            datasetTest: The testing dataset.
            featureDim: The feature dimension.
            n_gramRange: The n-gram range.
            path: The path to save the vectorized byte sequence.
        Returns:
            vectorzieTrain: The vectorized training dataset.
            vectorzieTest: The vectorized testing dataset.
            y_train_label: The label of the training dataset.
            y_test_label: The label of the testing dataset.
            label_mapping: The label mapping.
        '''
        train_file = f"{path}/vectorzieTrain.csv"
        test_file = f"{path}/vectorzieTest.csv"
        label_file = f"{path}/label_mapping.pkl"

        vectorzieTrainDf = datasetTrain[["file_name","CPU","family","byte_sequence"]]
        vectorzieTestDf = datasetTest[["file_name","CPU","family","byte_sequence"]]
        if os.path.exists(train_file) and os.path.exists(test_file) and os.path.exists(label_file):
            print(f"Loading vectorized byte sequence from {path}...")
            vectorzieTrainDf = pd.read_csv(train_file)
            vectorzieTestDf = pd.read_csv(test_file)
            with open(label_file, "rb") as f:
                label_mapping = pickle.load(f)
                f.close()
        elif not os.path.exists(path):
            print(f"Creating folder {path}...")
            self.detector.mkdir(path)

        col = f'tfidf_{featureDim}_{n_gramRange[0]}_{n_gramRange[1]}'
        ycol = 'y_label'
        feature_col = [f"{col}_{i}" for i in range(featureDim)]
        if feature_col[0] not in vectorzieTrainDf.columns or feature_col[0] not in vectorzieTestDf.columns or ycol not in vectorzieTrainDf.columns or ycol not in vectorzieTestDf.columns or label_file is None:
            print(f"Vectorizing byte sequence and saving to {path}...")
            byteSequenceTrain = datasetTrain['byte_sequence'].values
            byteSequenceTest = datasetTest['byte_sequence'].values
            y_train = datasetTrain['family'].values
            y_test = datasetTest['family'].values

            le = LabelEncoder()
            y_train_label, y_test_label, label_mapping = self._encode_labels(le, y_train, y_test)

            tfidf_vec = TfidfVectorizer(analyzer='word', ngram_range=n_gramRange, max_features=featureDim)
            tfidf_matrix_train = tfidf_vec.fit_transform(byteSequenceTrain)
            tfidf_matrix_test = tfidf_vec.transform(byteSequenceTest)

            vectorzieTrain = tfidf_matrix_train.toarray()
            vectorzieTest = tfidf_matrix_test.toarray()
            vectorzieTrainDf = pd.concat([
                vectorzieTrainDf,
                pd.DataFrame(vectorzieTrain, columns=feature_col, index=vectorzieTrainDf.index)
            ], axis=1)
            
            vectorzieTestDf = pd.concat([
                vectorzieTestDf,
                pd.DataFrame(vectorzieTest, columns=feature_col, index=vectorzieTestDf.index)
            ], axis=1)

            vectorzieTrainDf.loc[:, ycol] = y_train_label
            vectorzieTestDf.loc[:, ycol] = y_test_label
            print("Vectorizing byte sequence done.")
            vectorzieTrainDf.to_csv(train_file, index=False)
            vectorzieTestDf.to_csv(test_file, index=False)
            with open(label_file, "wb") as f:
                pickle.dump(label_mapping, f)
                f.close()
        else:
            # Load the vectorized byte sequence
            vectorzieTrain = vectorzieTrainDf[feature_col].values
            vectorzieTest = vectorzieTestDf[feature_col].values
            y_train_label = vectorzieTrainDf['y_label'].values
            y_test_label = vectorzieTestDf['y_label'].values
            with open(label_file, "rb") as f:
                label_mapping = pickle.load(f)
                f.close()
        
        print("vectorzieTrain shape:", vectorzieTrain.shape)
        print("vectorzieTest shape:", vectorzieTest.shape)
        print('label_mapping:', label_mapping)
        return vectorzieTrain, vectorzieTest, y_train_label, y_test_label, label_mapping, vectorzieTrainDf, vectorzieTestDf
    
    def _encode_labels(self, le: LabelEncoder, y_train: Any, y_test: Any) -> Tuple[Any, Any, dict]:
        le.fit(list(y_train) + list(y_test))
        y_train_label = le.transform(y_train)
        y_test_label = le.transform(y_test)
        label_mapping = {index: label for index, label in enumerate(le.classes_)}
        return y_train_label, y_test_label, label_mapping