from typing import Any, Tuple
import os
import pandas as pd
from pandas import DataFrame
from numpy import array
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
import pickle
import warnings
import torch
from prototypeLearning import prototypical_loss, prototypical_loss_using_proto
import numpy as np


class malwareDetector:
    '''
    This class is used to detect malware samples.
    '''
    def __init__(self, cluster: bool = True, train: bool = True, validation: bool = False,
                 cpuArch: str = "crossArch", seed: int = 7, 
                 support_shots = 5, query_shots = 5,
                 class_per_iter = 14,
                 epochs = 100, iterations = 100,
                 learning_rate = 0.001, dropout_prob = 0.3,
                 lr_scheduler = 20, lr_scheduler_gamma = 0.5,
                 hidden_size = 256, output_size = 64,
                 cuda = False):
        # Folder
        self.malwareFolder = "/home/mandy900619/data/Malware202403/"
        self.datasetFolder = "./dataset"
        self.modelFolder = "./model"
        self.embeddingFolder = "./embedding"
        self.clusterDataFolder = "./clusterData"
        self.clusterResultFolder = "./clusterResult"
        self.picFolder = "./pic"

        self.cluster = cluster
        self.train = train
        self.validation = validation
        self.cpuArch = cpuArch
        self.seed = seed

        self.support_shots = support_shots
        self.query_shots = query_shots
        self.class_per_iter = class_per_iter
        self.epochs = epochs
        self.iterations = iterations
        self.learning_rate = learning_rate
        self.lr_scheduler = lr_scheduler
        self.lr_scheduler_gamma = lr_scheduler_gamma
        self.dropout_prob = dropout_prob
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.cuda = cuda
        self.model_name = f"model_{cpuArch}_cluster_{cluster}"

    def mkdir(self, path: str) -> None:
        if not os.path.exists(path):
            os.makedirs(path)

    def trainModel(self, model, dataloader, optim, save_model=False, val_dataloader=None, new_label_mapping=None):
        
        if val_dataloader is None:
            best_state = None


        loss_min = 100
        train_loss = []
        train_acc = []
        val_loss = []
        val_acc = []
        best_acc = 0

        for epoch in range(self.epochs):
            print('=== Epoch: {} ==='.format(epoch))
            model.train()
            prototypes = dict()
            prototypesCounts = dict()
            for i, (data, labels) in enumerate(dataloader):
                optim.zero_grad()
                data = data.squeeze(1)
                data = data.float()
                embeddings = model(data)
                loss, acc, proto, protoID, _, _, _= prototypical_loss(embeddings, target=labels, n_support=self.support_shots)
                if self.cluster & val_dataloader is not None:
                    for i in range(proto.shape[0]):
                        if prototypesCounts.get(protoID[i].item()) is None:
                            prototypesCounts[protoID[i].item()] = 1
                            prototypes[protoID[i].item()] = proto[i]
                        else:
                            prototypesCounts[protoID[i].item()] += 1
                            prototypes[protoID[i].item()] += proto[i]
                loss.backward()
                optim.step()   
                train_loss.append(loss.item())
                train_acc.append(acc.item()) 
            if self.cluster & val_dataloader is not None:
                prototypes = {k: v / prototypesCounts[k] for k, v in prototypes.items()}
                prototypes = dict(sorted(prototypes.items()))
            avg_loss = np.mean(train_loss[-(self.iterations):])
            avg_acc = np.mean(train_acc[-(self.iterations):])
            postfix = ' (Best)' if avg_acc >= best_acc else ' (Best: {})'.format(best_acc)
            print('Avg Train Loss: {}, Avg Train Acc: {}{}'.format(avg_loss, avg_acc, postfix))
            lr_scheduler.step()
            if val_dataloader is not None:
                model.eval()
                for i, (data, labels) in enumerate(val_dataloader):
                    data = data.squeeze(1)
                    data = data.float()
                    model_output = model(data)
                    if self.cluster:
                        loss, acc, _= prototypical_loss_using_proto(model_output, target=labels, prototypes=prototypes, label_mapping=new_label_mapping)
                    else:
                        loss, acc, _, _, _, _, _= prototypical_loss(model_output, target=labels, n_support=self.support_shots)
                    val_loss.append(loss.item())
                    val_acc.append(acc.item())
                avg_loss = np.mean(val_loss[-(self.iterations):])
                avg_acc = np.mean(val_acc[-(self.iterations):])
                postfix = ' (Best)' if avg_acc >= best_acc else ' (Best: {})'.format(
                    best_acc)
                print('Avg Val Loss: {}, Avg Val Acc: {}{}'.format(avg_loss, avg_acc, postfix))
                
            if save_model and avg_acc > best_acc:
                torch.save(model.state_dict(), f"{self.modelFolder}/{self.model_name}.pt")
                best_acc = avg_acc
                best_state = model.state_dict()
            elif save_model and avg_loss < loss_min and avg_acc >= best_acc:
                torch.save(model.state_dict(), f"{self.modelFolder}/{self.model_name}.pt")
                best_acc = avg_acc
                best_state = model.state_dict()
                loss_min = avg_loss
                
            if save_model:
                torch.save(model.state_dict(), f"{self.modelFolder}/{self.model_name}_check_point.pt")

        return best_state, best_acc, train_loss, train_acc, val_loss, val_acc


    def test(self, test_dataloader, model, prototypes = None, new_label_mapping = None):
        '''
        Test the model trained with the prototypical learning algorithm
        '''
        device = 'cuda:0' if torch.cuda.is_available() and self.cuda else 'cpu'
        avg_acc = list()
        for epoch in range(10):
            for i, (x, y) in enumerate(test_dataloader):
                x, y = x.to(device), y.to(device)
                x = x.squeeze(1)
                x = x.float()
                model_output = model(x)
                if prototypes is None:
                    _, acc, _, _, _, _, _= prototypical_loss(model_output, target=y, n_support=self.support_shots)
                else:
                    _, acc, _= prototypical_loss_using_proto(model_output, target=y,prototypes=prototypes, label_mapping=new_label_mapping)
                avg_acc.append(acc.item())
        avg_acc = np.mean(avg_acc)
        print('Test Acc: {}'.format(avg_acc))

        return avg_acc

