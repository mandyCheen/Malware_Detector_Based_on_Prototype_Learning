{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all datasets...\n",
      "train dataset shape: (880, 14)\n",
      "train dataset family number: 44\n",
      "test dataset shape: (440, 14)\n",
      "test dataset family number: 22\n",
      "val dataset shape: (160, 14)\n",
      "val dataset family number: 8\n",
      "Vectorizing byte sequence using TF-IDF.\n"
     ]
    }
   ],
   "source": [
    "from malwareDetector import malwareDetector\n",
    "from dataLoader import DatasetLoad\n",
    "from byteSequenceVectorize import ByteSequenceVectorizer\n",
    "\n",
    "detector = malwareDetector(cluster=False, train=True, val=True, cpuArch=\"crossArchLabel\",\n",
    "                            support_shots=5, query_shots=5, class_per_iter=20, class_per_iter_test=5,\n",
    "                            loss=\"\", dropout_prob=0)\n",
    "\n",
    "dataset = DatasetLoad(detector)\n",
    "\n",
    "vectorize = ByteSequenceVectorizer(method = \"tfidf\", detector = detector, dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorize Method:  tfidf\n",
      "Loading vectorized byte sequence from ./embedding...\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorize Method: \", vectorize.vectorize_method)\n",
    "featureDim = 1000\n",
    "n_gramRange = (2, 4)\n",
    "\n",
    "train_X, test_X, val_X, train_y, test_y, val_y, train_map, test_map, val_map = vectorize.vectorize_func(featureDim, n_gramRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape:  (880, 1000) <class 'numpy.ndarray'>\n",
      "Train y shape:  (880,) <class 'numpy.ndarray'>\n",
      "Test X shape:  (440, 1000)\n",
      "Test y shape:  (440,)\n",
      "Val X shape:  (160, 1000)\n",
      "Val y shape:  (160,)\n",
      "Train Map:  {0: 'aenjaris_Advanced Micro Devices X86-64', 1: 'blueshell_Advanced Micro Devices X86-64', 2: 'bpfdoor_Advanced Micro Devices X86-64', 3: 'cobaltstrike_Advanced Micro Devices X86-64', 4: 'cornelgen_Intel 80386', 5: 'cryptonote_Advanced Micro Devices X86-64', 6: 'dnsamp_Advanced Micro Devices X86-64', 7: 'dnsamp_Intel 80386', 8: 'dnscat_Advanced Micro Devices X86-64', 9: 'dropperl_Advanced Micro Devices X86-64', 10: 'drtycow_Advanced Micro Devices X86-64', 11: 'equationdrug_Intel 80386', 12: 'exploitscan_Advanced Micro Devices X86-64', 13: 'ezuriloader_Advanced Micro Devices X86-64', 14: 'fscan_Advanced Micro Devices X86-64', 15: 'gafgyt_ARM', 16: 'gafgyt_Advanced Micro Devices X86-64', 17: 'hive_Advanced Micro Devices X86-64', 18: 'lady_Advanced Micro Devices X86-64', 19: 'malsource_Advanced Micro Devices X86-64', 20: 'merlin_Advanced Micro Devices X86-64', 21: 'mirai_ARM', 22: 'mirai_Advanced Micro Devices X86-64', 23: 'pnscan_Advanced Micro Devices X86-64', 24: 'pnscan_Intel 80386', 25: 'psybnc_Advanced Micro Devices X86-64', 26: 'race_Intel 80386', 27: 'rekoobe_Advanced Micro Devices X86-64', 28: 'reversessh_Advanced Micro Devices X86-64', 29: 'revproxy_Advanced Micro Devices X86-64', 30: 'rkit_Intel 80386', 31: 'sliver_Advanced Micro Devices X86-64', 32: 'sliver_Intel 80386', 33: 'sshbrute_Intel 80386', 34: 'sshdoor_Advanced Micro Devices X86-64', 35: 'sshdoor_Intel 80386', 36: 'triada_ARM', 37: 'tsunami_ARM', 38: 'tsunami_Advanced Micro Devices X86-64', 39: 'tsunami_Intel 80386', 40: 'tsunami_MIPS R3000', 41: 'winnti_Advanced Micro Devices X86-64', 42: 'zhtrap_ARM', 43: 'zhtrap_MIPS R3000'}\n",
      "Test Map:  {0: 'backegmm_Intel 80386', 1: 'chisel_Advanced Micro Devices X86-64', 2: 'exploitscan_Intel 80386', 3: 'fritzfrog_Advanced Micro Devices X86-64', 4: 'gafgyt_Intel 80386', 5: 'horsepill_Advanced Micro Devices X86-64', 6: 'kaiji_ARM', 7: 'kaiji_Advanced Micro Devices X86-64', 8: 'kaiji_Intel 80386', 9: 'local_Intel 80386', 10: 'malxmr_Advanced Micro Devices X86-64', 11: 'meterpreter_Advanced Micro Devices X86-64', 12: 'meterpreter_Intel 80386', 13: 'mirai_Intel 80386', 14: 'ngioweb_MIPS R3000', 15: 'prochider_Advanced Micro Devices X86-64', 16: 'prochider_Intel 80386', 17: 'stowaway_Advanced Micro Devices X86-64', 18: 'vpnfilter_MIPS R3000', 19: 'winexe_Advanced Micro Devices X86-64', 20: 'xmrig_Advanced Micro Devices X86-64', 21: 'xorddos_Intel 80386'}\n",
      "Val Map:  {0: 'camelot_Advanced Micro Devices X86-64', 1: 'cleanlog_Advanced Micro Devices X86-64', 2: 'gafgyt_MIPS R3000', 3: 'kaiji_MIPS R3000', 4: 'mirai_MIPS R3000', 5: 'poseidon_Advanced Micro Devices X86-64', 6: 'sckit_Intel 80386', 7: 'vtflooder_Advanced Micro Devices X86-64'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train X shape: \", train_X.shape, type(train_X))\n",
    "print(\"Train y shape: \", train_y.shape, type(train_y))\n",
    "print(\"Test X shape: \", test_X.shape)\n",
    "print(\"Test y shape: \", test_y.shape)\n",
    "if(val_X is not None):\n",
    "    print(\"Val X shape: \", val_X.shape)\n",
    "    print(\"Val y shape: \", val_y.shape)\n",
    "print(\"Train Map: \", train_map)\n",
    "print(\"Test Map: \", test_map)\n",
    "if(val_map is not None):\n",
    "    print(\"Val Map: \", val_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes per iteration: 20\n",
      "N-shot: 5\n",
      "=== Epoch: 0 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.8647621276974679, Avg Train Acc: 0.7192000019550323 (Best)\n",
      "Avg Val Loss: 0.2792599210236222, Avg Val Acc: 0.9066666674613952 (Best)\n",
      "Model saved at ./model/model_crossArchLabel_withVal.pt\n",
      "=== Epoch: 1 ===\n",
      "Avg Train Loss: 0.5568277426064014, Avg Train Acc: 0.8015000003576279 (Best: 0.9066666674613952)\n",
      "Avg Val Loss: 0.22234404414892198, Avg Val Acc: 0.9154666697978974 (Best)\n",
      "Model saved at ./model/model_crossArchLabel_withVal.pt\n",
      "=== Epoch: 2 ===\n",
      "Avg Train Loss: 0.4913013093173504, Avg Train Acc: 0.8240999960899353 (Best: 0.9154666697978974)\n",
      "Avg Val Loss: 0.2559166530240327, Avg Val Acc: 0.9152000021934509 (Best: 0.9154666697978974)\n",
      "=== Epoch: 3 ===\n",
      "Avg Train Loss: 0.4362224443256855, Avg Train Acc: 0.838600002527237 (Best: 0.9154666697978974)\n",
      "Avg Val Loss: 0.2398069803789258, Avg Val Acc: 0.9094666689634323 (Best: 0.9154666697978974)\n",
      "=== Epoch: 4 ===\n",
      "Avg Train Loss: 0.4706785801798105, Avg Train Acc: 0.8273999983072281 (Best: 0.9154666697978974)\n",
      "Avg Val Loss: 0.28274898959323763, Avg Val Acc: 0.9052000057697296 (Best: 0.9154666697978974)\n",
      "=== Epoch: 5 ===\n",
      "Avg Train Loss: 0.3885011439397931, Avg Train Acc: 0.8555000001192092 (Best: 0.9154666697978974)\n",
      "Avg Val Loss: 0.2641809342056513, Avg Val Acc: 0.9078666692972184 (Best: 0.9154666697978974)\n",
      "=== Epoch: 6 ===\n",
      "Avg Train Loss: 0.4181618320569396, Avg Train Acc: 0.8459000015258789 (Best: 0.9154666697978974)\n",
      "Avg Val Loss: 0.235751110073179, Avg Val Acc: 0.9140000009536743 (Best: 0.9154666697978974)\n",
      "=== Epoch: 7 ===\n",
      "Avg Train Loss: 0.42331199303269385, Avg Train Acc: 0.8383999985456466 (Best: 0.9154666697978974)\n",
      "Avg Val Loss: 0.2466868648119271, Avg Val Acc: 0.9204000049829483 (Best)\n",
      "Model saved at ./model/model_crossArchLabel_withVal.pt\n",
      "=== Epoch: 8 ===\n",
      "Avg Train Loss: 0.41326244801282885, Avg Train Acc: 0.8418999975919723 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.29751081831753257, Avg Val Acc: 0.8948000031709671 (Best: 0.9204000049829483)\n",
      "=== Epoch: 9 ===\n",
      "Avg Train Loss: 0.4089862331748009, Avg Train Acc: 0.843400000333786 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.22628277289681137, Avg Val Acc: 0.9132000035047532 (Best: 0.9204000049829483)\n",
      "=== Epoch: 10 ===\n",
      "Avg Train Loss: 0.38076397210359575, Avg Train Acc: 0.8527999985218048 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2694987139478326, Avg Val Acc: 0.9061333370208741 (Best: 0.9204000049829483)\n",
      "=== Epoch: 11 ===\n",
      "Avg Train Loss: 0.3767474237829447, Avg Train Acc: 0.8564999985694886 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.24152193132787944, Avg Val Acc: 0.91226666867733 (Best: 0.9204000049829483)\n",
      "=== Epoch: 12 ===\n",
      "Avg Train Loss: 0.3862105677649379, Avg Train Acc: 0.8530000001192093 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.24192517295479773, Avg Val Acc: 0.907466669678688 (Best: 0.9204000049829483)\n",
      "=== Epoch: 13 ===\n",
      "Avg Train Loss: 0.393187140673399, Avg Train Acc: 0.8463999986648559 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2505018262937665, Avg Val Acc: 0.9085333389043808 (Best: 0.9204000049829483)\n",
      "=== Epoch: 14 ===\n",
      "Avg Train Loss: 0.4179579719901085, Avg Train Acc: 0.8393999981880188 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.282674638684839, Avg Val Acc: 0.9009333354234695 (Best: 0.9204000049829483)\n",
      "=== Epoch: 15 ===\n",
      "Avg Train Loss: 0.3839673802256584, Avg Train Acc: 0.8522999984025955 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2701266131363809, Avg Val Acc: 0.9040000027418137 (Best: 0.9204000049829483)\n",
      "=== Epoch: 16 ===\n",
      "Avg Train Loss: 0.38628833919763567, Avg Train Acc: 0.8512999975681305 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.26249637007713317, Avg Val Acc: 0.9084000033140183 (Best: 0.9204000049829483)\n",
      "=== Epoch: 17 ===\n",
      "Avg Train Loss: 0.3731880979984999, Avg Train Acc: 0.8510999995470047 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.24116936882957815, Avg Val Acc: 0.9105333346128464 (Best: 0.9204000049829483)\n",
      "=== Epoch: 18 ===\n",
      "Avg Train Loss: 0.37886096522212026, Avg Train Acc: 0.8501999980211258 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.24750002186745404, Avg Val Acc: 0.9098666691780091 (Best: 0.9204000049829483)\n",
      "=== Epoch: 19 ===\n",
      "Avg Train Loss: 0.4084424629062414, Avg Train Acc: 0.8404999977350235 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2915844156593084, Avg Val Acc: 0.8916000026464462 (Best: 0.9204000049829483)\n",
      "=== Epoch: 20 ===\n",
      "Avg Train Loss: 0.4055814022477716, Avg Train Acc: 0.8455999976396561 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2764473577588797, Avg Val Acc: 0.9029333382844925 (Best: 0.9204000049829483)\n",
      "=== Epoch: 21 ===\n",
      "Avg Train Loss: 0.37209907967597244, Avg Train Acc: 0.8525000011920929 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.21568572159856558, Avg Val Acc: 0.9169333392381668 (Best: 0.9204000049829483)\n",
      "=== Epoch: 22 ===\n",
      "Avg Train Loss: 0.35484468914568423, Avg Train Acc: 0.8622999995946884 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.267731645135209, Avg Val Acc: 0.9058666676282883 (Best: 0.9204000049829483)\n",
      "=== Epoch: 23 ===\n",
      "Avg Train Loss: 0.3751040756329894, Avg Train Acc: 0.8572999978065491 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2617190627846867, Avg Val Acc: 0.9065333372354507 (Best: 0.9204000049829483)\n",
      "=== Epoch: 24 ===\n",
      "Avg Train Loss: 0.36449748374521734, Avg Train Acc: 0.8549000000953675 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.24267796100117267, Avg Val Acc: 0.9118666708469391 (Best: 0.9204000049829483)\n",
      "=== Epoch: 25 ===\n",
      "Avg Train Loss: 0.37307294029742477, Avg Train Acc: 0.8551999968290329 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2540803823620081, Avg Val Acc: 0.9041333371400833 (Best: 0.9204000049829483)\n",
      "=== Epoch: 26 ===\n",
      "Avg Train Loss: 0.3600335969775915, Avg Train Acc: 0.860699998140335 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.24874246997758745, Avg Val Acc: 0.9068000030517578 (Best: 0.9204000049829483)\n",
      "=== Epoch: 27 ===\n",
      "Avg Train Loss: 0.358293212801218, Avg Train Acc: 0.8575000005960465 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2666408016346395, Avg Val Acc: 0.8918666732311249 (Best: 0.9204000049829483)\n",
      "=== Epoch: 28 ===\n",
      "Avg Train Loss: 0.36082588493824, Avg Train Acc: 0.8609999966621399 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.30526014843024313, Avg Val Acc: 0.8908000046014786 (Best: 0.9204000049829483)\n",
      "=== Epoch: 29 ===\n",
      "Avg Train Loss: 0.3597226787172258, Avg Train Acc: 0.8589000010490417 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2719751260336489, Avg Val Acc: 0.8990666675567627 (Best: 0.9204000049829483)\n",
      "=== Epoch: 30 ===\n",
      "Avg Train Loss: 0.3745391676016152, Avg Train Acc: 0.8506000000238418 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.29023227797821166, Avg Val Acc: 0.905866670012474 (Best: 0.9204000049829483)\n",
      "=== Epoch: 31 ===\n",
      "Avg Train Loss: 0.36101236335933207, Avg Train Acc: 0.8610000002384186 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2554466453846544, Avg Val Acc: 0.9040000051259994 (Best: 0.9204000049829483)\n",
      "=== Epoch: 32 ===\n",
      "Avg Train Loss: 0.3656968061067164, Avg Train Acc: 0.8635000002384186 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.23791754473932086, Avg Val Acc: 0.9133333349227906 (Best: 0.9204000049829483)\n",
      "=== Epoch: 33 ===\n",
      "Avg Train Loss: 0.3501448310166597, Avg Train Acc: 0.8608000034093857 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.26625165466219186, Avg Val Acc: 0.898266669511795 (Best: 0.9204000049829483)\n",
      "=== Epoch: 34 ===\n",
      "Avg Train Loss: 0.3830996431410313, Avg Train Acc: 0.851700000166893 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.27569257432594896, Avg Val Acc: 0.9033333390951157 (Best: 0.9204000049829483)\n",
      "=== Epoch: 35 ===\n",
      "Avg Train Loss: 0.35568818405270575, Avg Train Acc: 0.8612000000476837 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2581159435212612, Avg Val Acc: 0.9057333374023437 (Best: 0.9204000049829483)\n",
      "=== Epoch: 36 ===\n",
      "Avg Train Loss: 0.33894458021968604, Avg Train Acc: 0.8688000023365021 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.24085408476181328, Avg Val Acc: 0.9092000031471252 (Best: 0.9204000049829483)\n",
      "=== Epoch: 37 ===\n",
      "Avg Train Loss: 0.3482293533533812, Avg Train Acc: 0.8643000024557114 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.28408868964761497, Avg Val Acc: 0.8953333389759064 (Best: 0.9204000049829483)\n",
      "=== Epoch: 38 ===\n",
      "Avg Train Loss: 0.39576367400586604, Avg Train Acc: 0.8420999985933304 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.27560581871308387, Avg Val Acc: 0.8981333345174789 (Best: 0.9204000049829483)\n",
      "=== Epoch: 39 ===\n",
      "Avg Train Loss: 0.3629143886268139, Avg Train Acc: 0.8621000009775162 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.23509782924316824, Avg Val Acc: 0.9108000034093857 (Best: 0.9204000049829483)\n",
      "=== Epoch: 40 ===\n",
      "Avg Train Loss: 0.3637004185654223, Avg Train Acc: 0.8537999999523163 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.24017105426639318, Avg Val Acc: 0.9101333391666412 (Best: 0.9204000049829483)\n",
      "=== Epoch: 41 ===\n",
      "Avg Train Loss: 0.3582312091998756, Avg Train Acc: 0.8593000006675721 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.26054487776011226, Avg Val Acc: 0.8986666691303253 (Best: 0.9204000049829483)\n",
      "=== Epoch: 42 ===\n",
      "Avg Train Loss: 0.3723292263969779, Avg Train Acc: 0.8560999995470047 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.25425582165829835, Avg Val Acc: 0.9048000025749207 (Best: 0.9204000049829483)\n",
      "=== Epoch: 43 ===\n",
      "Avg Train Loss: 0.37222963586449626, Avg Train Acc: 0.8559999972581863 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2955500016734004, Avg Val Acc: 0.8946666711568833 (Best: 0.9204000049829483)\n",
      "=== Epoch: 44 ===\n",
      "Avg Train Loss: 0.35517670104280114, Avg Train Acc: 0.8611999994516373 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2652429717592895, Avg Val Acc: 0.9008000028133393 (Best: 0.9204000049829483)\n",
      "=== Epoch: 45 ===\n",
      "Avg Train Loss: 0.3497367850318551, Avg Train Acc: 0.8615000009536743 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2763897608686239, Avg Val Acc: 0.8918666690587997 (Best: 0.9204000049829483)\n",
      "=== Epoch: 46 ===\n",
      "Avg Train Loss: 0.3715781836211681, Avg Train Acc: 0.8559999996423722 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2699893716350198, Avg Val Acc: 0.9020000022649765 (Best: 0.9204000049829483)\n",
      "=== Epoch: 47 ===\n",
      "Avg Train Loss: 0.37819747388362884, Avg Train Acc: 0.8524999958276749 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.27279088175855576, Avg Val Acc: 0.8976000046730042 (Best: 0.9204000049829483)\n",
      "=== Epoch: 48 ===\n",
      "Avg Train Loss: 0.3739903062582016, Avg Train Acc: 0.8542999947071075 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.24230919970199466, Avg Val Acc: 0.9075999999046326 (Best: 0.9204000049829483)\n",
      "=== Epoch: 49 ===\n",
      "Avg Train Loss: 0.361882498934865, Avg Train Acc: 0.8574999988079071 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.265105548016727, Avg Val Acc: 0.8974666714668273 (Best: 0.9204000049829483)\n",
      "=== Epoch: 50 ===\n",
      "Avg Train Loss: 0.36350509501993655, Avg Train Acc: 0.8548999983072281 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.24715878192335367, Avg Val Acc: 0.9046666693687438 (Best: 0.9204000049829483)\n",
      "=== Epoch: 51 ===\n",
      "Avg Train Loss: 0.36551574429962785, Avg Train Acc: 0.8598999983072281 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2430657036975026, Avg Val Acc: 0.9064000016450882 (Best: 0.9204000049829483)\n",
      "=== Epoch: 52 ===\n",
      "Avg Train Loss: 0.3842380728758872, Avg Train Acc: 0.8525999993085861 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2388918710825965, Avg Val Acc: 0.9118666696548462 (Best: 0.9204000049829483)\n",
      "=== Epoch: 53 ===\n",
      "Avg Train Loss: 0.33679199109785257, Avg Train Acc: 0.865300001502037 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2250034041889012, Avg Val Acc: 0.9134666669368744 (Best: 0.9204000049829483)\n",
      "=== Epoch: 54 ===\n",
      "Avg Train Loss: 0.35974172845482827, Avg Train Acc: 0.8576999998092651 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2668030542880297, Avg Val Acc: 0.9016000020503998 (Best: 0.9204000049829483)\n",
      "=== Epoch: 55 ===\n",
      "Avg Train Loss: 0.3671362683176994, Avg Train Acc: 0.8581000012159348 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.24869267553091048, Avg Val Acc: 0.900933336019516 (Best: 0.9204000049829483)\n",
      "=== Epoch: 56 ===\n",
      "Avg Train Loss: 0.36247339867055417, Avg Train Acc: 0.8606999999284745 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2444774156436324, Avg Val Acc: 0.9094666719436646 (Best: 0.9204000049829483)\n",
      "=== Epoch: 57 ===\n",
      "Avg Train Loss: 0.38577784355729816, Avg Train Acc: 0.8505999964475631 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2738003596197814, Avg Val Acc: 0.9002666682004928 (Best: 0.9204000049829483)\n",
      "=== Epoch: 58 ===\n",
      "Avg Train Loss: 0.35572541277855635, Avg Train Acc: 0.8630000001192093 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2781707440223545, Avg Val Acc: 0.8989333367347717 (Best: 0.9204000049829483)\n",
      "=== Epoch: 59 ===\n",
      "Avg Train Loss: 0.3739687443524599, Avg Train Acc: 0.8551999998092651 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.23898665975779296, Avg Val Acc: 0.9077333337068558 (Best: 0.9204000049829483)\n",
      "=== Epoch: 60 ===\n",
      "Avg Train Loss: 0.3445898336917162, Avg Train Acc: 0.8609999996423722 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2274504357855767, Avg Val Acc: 0.9144000041484833 (Best: 0.9204000049829483)\n",
      "=== Epoch: 61 ===\n",
      "Avg Train Loss: 0.37846172774210574, Avg Train Acc: 0.8554000008106232 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.25848432164639235, Avg Val Acc: 0.9074666690826416 (Best: 0.9204000049829483)\n",
      "=== Epoch: 62 ===\n",
      "Avg Train Loss: 0.35676351068541406, Avg Train Acc: 0.8575999993085861 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2894518536608666, Avg Val Acc: 0.8940000027418137 (Best: 0.9204000049829483)\n",
      "=== Epoch: 63 ===\n",
      "Avg Train Loss: 0.37491190910339356, Avg Train Acc: 0.8519999974966049 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.26610072599723933, Avg Val Acc: 0.8992000031471252 (Best: 0.9204000049829483)\n",
      "=== Epoch: 64 ===\n",
      "Avg Train Loss: 0.35606556814163925, Avg Train Acc: 0.8590000015497208 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.22009714148938656, Avg Val Acc: 0.9146666705608368 (Best: 0.9204000049829483)\n",
      "=== Epoch: 65 ===\n",
      "Avg Train Loss: 0.37226608069613576, Avg Train Acc: 0.8555999970436097 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.24814011826179921, Avg Val Acc: 0.9066666668653488 (Best: 0.9204000049829483)\n",
      "=== Epoch: 66 ===\n",
      "Avg Train Loss: 0.36190199144184587, Avg Train Acc: 0.8590000015497208 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.26947348201647403, Avg Val Acc: 0.9040000039339066 (Best: 0.9204000049829483)\n",
      "=== Epoch: 67 ===\n",
      "Avg Train Loss: 0.3866007696837187, Avg Train Acc: 0.8509999996423722 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.22775283645838498, Avg Val Acc: 0.9157333362102509 (Best: 0.9204000049829483)\n",
      "=== Epoch: 68 ===\n",
      "Avg Train Loss: 0.3674185413308442, Avg Train Acc: 0.8555999976396561 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.291259913565591, Avg Val Acc: 0.8880000019073486 (Best: 0.9204000049829483)\n",
      "=== Epoch: 69 ===\n",
      "Avg Train Loss: 0.32946170508861544, Avg Train Acc: 0.8677000039815903 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.23660264169797302, Avg Val Acc: 0.9057333368062973 (Best: 0.9204000049829483)\n",
      "=== Epoch: 70 ===\n",
      "Avg Train Loss: 0.35282961145043373, Avg Train Acc: 0.8602000004053116 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.23648317445069553, Avg Val Acc: 0.9033333349227906 (Best: 0.9204000049829483)\n",
      "=== Epoch: 71 ===\n",
      "Avg Train Loss: 0.3390335274487734, Avg Train Acc: 0.86450000166893 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2592265550792217, Avg Val Acc: 0.898800003528595 (Best: 0.9204000049829483)\n",
      "=== Epoch: 72 ===\n",
      "Avg Train Loss: 0.36328056156635286, Avg Train Acc: 0.8590000027418137 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.25880960081703963, Avg Val Acc: 0.9016000020503998 (Best: 0.9204000049829483)\n",
      "=== Epoch: 73 ===\n",
      "Avg Train Loss: 0.37274665635079146, Avg Train Acc: 0.854200000166893 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.24839094892144203, Avg Val Acc: 0.9102666699886321 (Best: 0.9204000049829483)\n",
      "=== Epoch: 74 ===\n",
      "Avg Train Loss: 0.3251306063961238, Avg Train Acc: 0.8713999998569488 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.26563503470271826, Avg Val Acc: 0.897200003862381 (Best: 0.9204000049829483)\n",
      "=== Epoch: 75 ===\n",
      "Avg Train Loss: 0.37306859776377677, Avg Train Acc: 0.8582000023126602 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2644119484722614, Avg Val Acc: 0.9008000010251999 (Best: 0.9204000049829483)\n",
      "=== Epoch: 76 ===\n",
      "Avg Train Loss: 0.35818292386829853, Avg Train Acc: 0.8615000021457672 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2757734181173146, Avg Val Acc: 0.9013333350419999 (Best: 0.9204000049829483)\n",
      "=== Epoch: 77 ===\n",
      "Avg Train Loss: 0.36203032299876214, Avg Train Acc: 0.8596000015735626 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2572359203360975, Avg Val Acc: 0.9045333367586136 (Best: 0.9204000049829483)\n",
      "=== Epoch: 78 ===\n",
      "Avg Train Loss: 0.3774900839477777, Avg Train Acc: 0.8558999997377396 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2600294974818826, Avg Val Acc: 0.9045333355665207 (Best: 0.9204000049829483)\n",
      "=== Epoch: 79 ===\n",
      "Avg Train Loss: 0.35045931074768305, Avg Train Acc: 0.8620999991893769 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.24869275340810418, Avg Val Acc: 0.9074666690826416 (Best: 0.9204000049829483)\n",
      "=== Epoch: 80 ===\n",
      "Avg Train Loss: 0.3609963056445122, Avg Train Acc: 0.8555000025033951 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.263662614794448, Avg Val Acc: 0.9026666700839996 (Best: 0.9204000049829483)\n",
      "=== Epoch: 81 ===\n",
      "Avg Train Loss: 0.3588144749403, Avg Train Acc: 0.8581000018119812 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2525390086416155, Avg Val Acc: 0.9077333354949951 (Best: 0.9204000049829483)\n",
      "=== Epoch: 82 ===\n",
      "Avg Train Loss: 0.38157361809164286, Avg Train Acc: 0.8458999973535538 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.25170858432538806, Avg Val Acc: 0.902000002861023 (Best: 0.9204000049829483)\n",
      "=== Epoch: 83 ===\n",
      "Avg Train Loss: 0.3813194288313389, Avg Train Acc: 0.8473000013828278 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.284848856870085, Avg Val Acc: 0.8956000018119812 (Best: 0.9204000049829483)\n",
      "=== Epoch: 84 ===\n",
      "Avg Train Loss: 0.37401528656482697, Avg Train Acc: 0.8501999998092651 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2650782585516572, Avg Val Acc: 0.9004000043869018 (Best: 0.9204000049829483)\n",
      "=== Epoch: 85 ===\n",
      "Avg Train Loss: 0.3760349690914154, Avg Train Acc: 0.8543999999761581 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2694634302519262, Avg Val Acc: 0.9026666694879532 (Best: 0.9204000049829483)\n",
      "=== Epoch: 86 ===\n",
      "Avg Train Loss: 0.3630588323622942, Avg Train Acc: 0.8568999987840652 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.25370350152254106, Avg Val Acc: 0.9020000004768371 (Best: 0.9204000049829483)\n",
      "=== Epoch: 87 ===\n",
      "Avg Train Loss: 0.3448213176801801, Avg Train Acc: 0.8654000014066696 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2329465889185667, Avg Val Acc: 0.911600005030632 (Best: 0.9204000049829483)\n",
      "=== Epoch: 88 ===\n",
      "Avg Train Loss: 0.41472073428332806, Avg Train Acc: 0.8369999992847442 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2673237077891827, Avg Val Acc: 0.9033333367109299 (Best: 0.9204000049829483)\n",
      "=== Epoch: 89 ===\n",
      "Avg Train Loss: 0.3725383267831057, Avg Train Acc: 0.852600000500679 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.26522870764136314, Avg Val Acc: 0.8993333351612091 (Best: 0.9204000049829483)\n",
      "=== Epoch: 90 ===\n",
      "Avg Train Loss: 0.3403629887662828, Avg Train Acc: 0.8661999988555908 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2471746464446187, Avg Val Acc: 0.9084000033140183 (Best: 0.9204000049829483)\n",
      "=== Epoch: 91 ===\n",
      "Avg Train Loss: 0.35397925540804864, Avg Train Acc: 0.8598999983072281 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2790714162401855, Avg Val Acc: 0.9014666664600373 (Best: 0.9204000049829483)\n",
      "=== Epoch: 92 ===\n",
      "Avg Train Loss: 0.35233083680272104, Avg Train Acc: 0.8559000009298324 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2574148757196963, Avg Val Acc: 0.8997333389520645 (Best: 0.9204000049829483)\n",
      "=== Epoch: 93 ===\n",
      "Avg Train Loss: 0.37565487490966915, Avg Train Acc: 0.8551999980211258 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2612703706230968, Avg Val Acc: 0.8966666692495346 (Best: 0.9204000049829483)\n",
      "=== Epoch: 94 ===\n",
      "Avg Train Loss: 0.3501417274028063, Avg Train Acc: 0.8586000007390976 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2622626014426351, Avg Val Acc: 0.9020000010728836 (Best: 0.9204000049829483)\n",
      "=== Epoch: 95 ===\n",
      "Avg Train Loss: 0.35944406256079675, Avg Train Acc: 0.8566000008583069 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.23758387931622565, Avg Val Acc: 0.9102666717767716 (Best: 0.9204000049829483)\n",
      "=== Epoch: 96 ===\n",
      "Avg Train Loss: 0.3568083446100354, Avg Train Acc: 0.8616000008583069 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2880774583667517, Avg Val Acc: 0.9004000025987625 (Best: 0.9204000049829483)\n",
      "=== Epoch: 97 ===\n",
      "Avg Train Loss: 0.36867620412260294, Avg Train Acc: 0.8535000014305115 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2576860282756388, Avg Val Acc: 0.9045333367586136 (Best: 0.9204000049829483)\n",
      "=== Epoch: 98 ===\n",
      "Avg Train Loss: 0.36029227532446384, Avg Train Acc: 0.8528999954462051 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2501942388527095, Avg Val Acc: 0.9084000051021576 (Best: 0.9204000049829483)\n",
      "=== Epoch: 99 ===\n",
      "Avg Train Loss: 0.33671306708827614, Avg Train Acc: 0.8686000001430512 (Best: 0.9204000049829483)\n",
      "Avg Val Loss: 0.2609952403232455, Avg Val Acc: 0.9093333369493485 (Best: 0.9204000049829483)\n"
     ]
    }
   ],
   "source": [
    "if detector.train:\n",
    "    detector.trainModel(train_X=train_X, train_Y = train_y, val_X=val_X, val_Y=val_y, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.8816266696453094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8816266696453094"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.testModel(test_X=test_X, test_Y=test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning\n",
    "\n",
    "X = test_X\n",
    "y = test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import combinations\n",
    "\n",
    "def run_experiment(X, y, n_experiments=100):\n",
    "    classes = np.unique(y)\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    for _ in range(n_experiments):\n",
    "        # 隨機選擇5個類別\n",
    "        selected_classes = np.random.choice(classes, 5, replace=False)\n",
    "        \n",
    "        train_indices = []\n",
    "        test_indices = []\n",
    "        \n",
    "        for cls in selected_classes:\n",
    "            cls_indices = np.where(y == cls)[0]\n",
    "            train_indices.extend(np.random.choice(cls_indices, 5, replace=False))\n",
    "            test_indices.extend([idx for idx in cls_indices if idx not in train_indices])\n",
    "\n",
    "        X_train, y_train = X[train_indices], y[train_indices]\n",
    "        X_test, y_test = X[test_indices], y[test_indices]\n",
    "\n",
    "        # 訓練SVM\n",
    "        svm = SVC(kernel='rbf', gamma='scale')\n",
    "        svm.fit(X_train, y_train)\n",
    "        \n",
    "        # 預測並計算準確率\n",
    "        y_pred = svm.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    return np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 5-way 5-shot accuracy: 0.8801\n"
     ]
    }
   ],
   "source": [
    "avg_accuracy = run_experiment(X, y)\n",
    "print(f\"Average 5-way 5-shot accuracy: {avg_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byteSequence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
