{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all datasets...\n",
      "train dataset shape: (880, 14)\n",
      "train dataset family number: 44\n",
      "test dataset shape: (440, 14)\n",
      "test dataset family number: 22\n",
      "val dataset shape: (160, 14)\n",
      "val dataset family number: 8\n",
      "Vectorizing byte sequence using TF-IDF.\n"
     ]
    }
   ],
   "source": [
    "from malwareDetector import malwareDetector\n",
    "from dataLoader import DatasetLoad\n",
    "from byteSequenceVectorize import ByteSequenceVectorizer\n",
    "\n",
    "detector = malwareDetector(cluster=False, train=True, val=True, cpuArch=\"crossArchLabel\",\n",
    "                            support_shots=5, query_shots=5, class_per_iter=20, class_per_iter_test=5,\n",
    "                            loss=\"nn_prototypical\", dropout_prob=0.5)\n",
    "\n",
    "dataset = DatasetLoad(detector)\n",
    "\n",
    "vectorize = ByteSequenceVectorizer(method = \"tfidf\", detector = detector, dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorize Method:  tfidf\n",
      "Loading vectorized byte sequence from ./embedding...\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorize Method: \", vectorize.vectorize_method)\n",
    "featureDim = 1000\n",
    "n_gramRange = (2, 4)\n",
    "\n",
    "train_X, test_X, val_X, train_y, test_y, val_y, train_map, test_map, val_map = vectorize.vectorize_func(featureDim, n_gramRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape:  (880, 1000) <class 'numpy.ndarray'>\n",
      "Train y shape:  (880,) <class 'numpy.ndarray'>\n",
      "Test X shape:  (440, 1000)\n",
      "Test y shape:  (440,)\n",
      "Val X shape:  (160, 1000)\n",
      "Val y shape:  (160,)\n",
      "Train Map:  {0: 'aenjaris_Advanced Micro Devices X86-64', 1: 'blueshell_Advanced Micro Devices X86-64', 2: 'bpfdoor_Advanced Micro Devices X86-64', 3: 'cobaltstrike_Advanced Micro Devices X86-64', 4: 'cornelgen_Intel 80386', 5: 'cryptonote_Advanced Micro Devices X86-64', 6: 'dnsamp_Advanced Micro Devices X86-64', 7: 'dnsamp_Intel 80386', 8: 'dnscat_Advanced Micro Devices X86-64', 9: 'dropperl_Advanced Micro Devices X86-64', 10: 'drtycow_Advanced Micro Devices X86-64', 11: 'equationdrug_Intel 80386', 12: 'exploitscan_Advanced Micro Devices X86-64', 13: 'ezuriloader_Advanced Micro Devices X86-64', 14: 'fscan_Advanced Micro Devices X86-64', 15: 'gafgyt_ARM', 16: 'gafgyt_Advanced Micro Devices X86-64', 17: 'hive_Advanced Micro Devices X86-64', 18: 'lady_Advanced Micro Devices X86-64', 19: 'malsource_Advanced Micro Devices X86-64', 20: 'merlin_Advanced Micro Devices X86-64', 21: 'mirai_ARM', 22: 'mirai_Advanced Micro Devices X86-64', 23: 'pnscan_Advanced Micro Devices X86-64', 24: 'pnscan_Intel 80386', 25: 'psybnc_Advanced Micro Devices X86-64', 26: 'race_Intel 80386', 27: 'rekoobe_Advanced Micro Devices X86-64', 28: 'reversessh_Advanced Micro Devices X86-64', 29: 'revproxy_Advanced Micro Devices X86-64', 30: 'rkit_Intel 80386', 31: 'sliver_Advanced Micro Devices X86-64', 32: 'sliver_Intel 80386', 33: 'sshbrute_Intel 80386', 34: 'sshdoor_Advanced Micro Devices X86-64', 35: 'sshdoor_Intel 80386', 36: 'triada_ARM', 37: 'tsunami_ARM', 38: 'tsunami_Advanced Micro Devices X86-64', 39: 'tsunami_Intel 80386', 40: 'tsunami_MIPS R3000', 41: 'winnti_Advanced Micro Devices X86-64', 42: 'zhtrap_ARM', 43: 'zhtrap_MIPS R3000'}\n",
      "Test Map:  {0: 'backegmm_Intel 80386', 1: 'chisel_Advanced Micro Devices X86-64', 2: 'exploitscan_Intel 80386', 3: 'fritzfrog_Advanced Micro Devices X86-64', 4: 'gafgyt_Intel 80386', 5: 'horsepill_Advanced Micro Devices X86-64', 6: 'kaiji_ARM', 7: 'kaiji_Advanced Micro Devices X86-64', 8: 'kaiji_Intel 80386', 9: 'local_Intel 80386', 10: 'malxmr_Advanced Micro Devices X86-64', 11: 'meterpreter_Advanced Micro Devices X86-64', 12: 'meterpreter_Intel 80386', 13: 'mirai_Intel 80386', 14: 'ngioweb_MIPS R3000', 15: 'prochider_Advanced Micro Devices X86-64', 16: 'prochider_Intel 80386', 17: 'stowaway_Advanced Micro Devices X86-64', 18: 'vpnfilter_MIPS R3000', 19: 'winexe_Advanced Micro Devices X86-64', 20: 'xmrig_Advanced Micro Devices X86-64', 21: 'xorddos_Intel 80386'}\n",
      "Val Map:  {0: 'camelot_Advanced Micro Devices X86-64', 1: 'cleanlog_Advanced Micro Devices X86-64', 2: 'gafgyt_MIPS R3000', 3: 'kaiji_MIPS R3000', 4: 'mirai_MIPS R3000', 5: 'poseidon_Advanced Micro Devices X86-64', 6: 'sckit_Intel 80386', 7: 'vtflooder_Advanced Micro Devices X86-64'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train X shape: \", train_X.shape, type(train_X))\n",
    "print(\"Train y shape: \", train_y.shape, type(train_y))\n",
    "print(\"Test X shape: \", test_X.shape)\n",
    "print(\"Test y shape: \", test_y.shape)\n",
    "if(val_X is not None):\n",
    "    print(\"Val X shape: \", val_X.shape)\n",
    "    print(\"Val y shape: \", val_y.shape)\n",
    "print(\"Train Map: \", train_map)\n",
    "print(\"Test Map: \", test_map)\n",
    "if(val_map is not None):\n",
    "    print(\"Val Map: \", val_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes per iteration: 20\n",
      "N-shot: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mandy900619/anaconda3/envs/smell/lib/python3.11/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/mandy900619/anaconda3/envs/smell/lib/python3.11/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "=== Epoch: 0 ===\n",
      "Avg Train Loss: 1.6280057340860368, Avg Train Acc: 0.4346999998390675 (Best)\n",
      "Avg Val Loss: 0.29169172890484335, Avg Val Acc: 0.9112000030279159 (Best)\n",
      "Model saved at ./model/model_crossArchLabel_nn_prototypical_withVal.pt\n",
      "=== Epoch: 1 ===\n",
      "Avg Train Loss: 1.164648665189743, Avg Train Acc: 0.5609999999403954 (Best: 0.9112000030279159)\n",
      "Avg Val Loss: 0.2403058000281453, Avg Val Acc: 0.9138666713237762 (Best)\n",
      "Model saved at ./model/model_crossArchLabel_nn_prototypical_withVal.pt\n",
      "=== Epoch: 2 ===\n",
      "Avg Train Loss: 1.065204827785492, Avg Train Acc: 0.6071999990940093 (Best: 0.9138666713237762)\n",
      "Avg Val Loss: 0.2207666583545506, Avg Val Acc: 0.9365333372354507 (Best)\n",
      "Model saved at ./model/model_crossArchLabel_nn_prototypical_withVal.pt\n",
      "=== Epoch: 3 ===\n",
      "Avg Train Loss: 0.9660136574506759, Avg Train Acc: 0.6250000005960464 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.2379854499269277, Avg Val Acc: 0.9156000036001205 (Best: 0.9365333372354507)\n",
      "=== Epoch: 4 ===\n",
      "Avg Train Loss: 0.8493975821137428, Avg Train Acc: 0.6538000029325485 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.20655021513346583, Avg Val Acc: 0.923200004696846 (Best: 0.9365333372354507)\n",
      "=== Epoch: 5 ===\n",
      "Avg Train Loss: 0.7640246033668519, Avg Train Acc: 0.6822999984025955 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.22748993260785938, Avg Val Acc: 0.926933336853981 (Best: 0.9365333372354507)\n",
      "=== Epoch: 6 ===\n",
      "Avg Train Loss: 0.7097535854578019, Avg Train Acc: 0.6989000004529953 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3079366232920438, Avg Val Acc: 0.9042666697502136 (Best: 0.9365333372354507)\n",
      "=== Epoch: 7 ===\n",
      "Avg Train Loss: 0.6544418649375439, Avg Train Acc: 0.7290000009536743 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.30817733274772763, Avg Val Acc: 0.9072000044584274 (Best: 0.9365333372354507)\n",
      "=== Epoch: 8 ===\n",
      "Avg Train Loss: 0.6604560375213623, Avg Train Acc: 0.7252999991178513 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3973760620690882, Avg Val Acc: 0.8886666685342789 (Best: 0.9365333372354507)\n",
      "=== Epoch: 9 ===\n",
      "Avg Train Loss: 0.6208815172314643, Avg Train Acc: 0.7420999991893769 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3117130059469491, Avg Val Acc: 0.9085333395004273 (Best: 0.9365333372354507)\n",
      "=== Epoch: 10 ===\n",
      "Avg Train Loss: 0.6072114415466785, Avg Train Acc: 0.746599999666214 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3200125128217042, Avg Val Acc: 0.8997333347797394 (Best: 0.9365333372354507)\n",
      "=== Epoch: 11 ===\n",
      "Avg Train Loss: 0.6232461784780026, Avg Train Acc: 0.7368999993801117 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.26039291952736676, Avg Val Acc: 0.921600005030632 (Best: 0.9365333372354507)\n",
      "=== Epoch: 12 ===\n",
      "Avg Train Loss: 0.5942775419354439, Avg Train Acc: 0.7501999998092651 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.2473230045195669, Avg Val Acc: 0.9253333342075348 (Best: 0.9365333372354507)\n",
      "=== Epoch: 13 ===\n",
      "Avg Train Loss: 0.5537052749097348, Avg Train Acc: 0.7614000016450881 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.43514989426825196, Avg Val Acc: 0.9122666710615158 (Best: 0.9365333372354507)\n",
      "=== Epoch: 14 ===\n",
      "Avg Train Loss: 0.5752077379822731, Avg Train Acc: 0.762999997138977 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.2879662654781714, Avg Val Acc: 0.9170666682720184 (Best: 0.9365333372354507)\n",
      "=== Epoch: 15 ===\n",
      "Avg Train Loss: 0.5685971373319626, Avg Train Acc: 0.7584000009298325 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.27146249620243906, Avg Val Acc: 0.9129333341121674 (Best: 0.9365333372354507)\n",
      "=== Epoch: 16 ===\n",
      "Avg Train Loss: 0.5574789768457413, Avg Train Acc: 0.7601999974250794 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3796970132365823, Avg Val Acc: 0.9045333355665207 (Best: 0.9365333372354507)\n",
      "=== Epoch: 17 ===\n",
      "Avg Train Loss: 0.5670918864011765, Avg Train Acc: 0.7631999999284744 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.25845088296569885, Avg Val Acc: 0.9114666676521301 (Best: 0.9365333372354507)\n",
      "=== Epoch: 18 ===\n",
      "Avg Train Loss: 0.5705162620544434, Avg Train Acc: 0.7568000030517578 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.37629550863057376, Avg Val Acc: 0.8964000004529953 (Best: 0.9365333372354507)\n",
      "=== Epoch: 19 ===\n",
      "Avg Train Loss: 0.5419790422916413, Avg Train Acc: 0.7682000023126602 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.38886424774304035, Avg Val Acc: 0.8881333363056183 (Best: 0.9365333372354507)\n",
      "=== Epoch: 20 ===\n",
      "Avg Train Loss: 0.5003954821079969, Avg Train Acc: 0.7766999989748001 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3099225065484643, Avg Val Acc: 0.8941333371400834 (Best: 0.9365333372354507)\n",
      "=== Epoch: 21 ===\n",
      "Avg Train Loss: 0.5052831599116325, Avg Train Acc: 0.7810999989509583 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3512334528565407, Avg Val Acc: 0.8969333386421203 (Best: 0.9365333372354507)\n",
      "=== Epoch: 22 ===\n",
      "Avg Train Loss: 0.5185954654216767, Avg Train Acc: 0.7775999975204467 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3720145776402205, Avg Val Acc: 0.8874666684865952 (Best: 0.9365333372354507)\n",
      "=== Epoch: 23 ===\n",
      "Avg Train Loss: 0.5200370959937572, Avg Train Acc: 0.7783000010251999 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.42677631705999375, Avg Val Acc: 0.8982666689157486 (Best: 0.9365333372354507)\n",
      "=== Epoch: 24 ===\n",
      "Avg Train Loss: 0.5166638173162937, Avg Train Acc: 0.7810999995470047 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4566414393298328, Avg Val Acc: 0.8833333390951157 (Best: 0.9365333372354507)\n",
      "=== Epoch: 25 ===\n",
      "Avg Train Loss: 0.48435094103217124, Avg Train Acc: 0.7939000034332275 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3798096933029592, Avg Val Acc: 0.8892000025510788 (Best: 0.9365333372354507)\n",
      "=== Epoch: 26 ===\n",
      "Avg Train Loss: 0.49638461593538524, Avg Train Acc: 0.7840000009536743 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.38876595091074706, Avg Val Acc: 0.8932000023126602 (Best: 0.9365333372354507)\n",
      "=== Epoch: 27 ===\n",
      "Avg Train Loss: 0.4912270641326904, Avg Train Acc: 0.7883999985456467 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.45491170544177295, Avg Val Acc: 0.8770666694641114 (Best: 0.9365333372354507)\n",
      "=== Epoch: 28 ===\n",
      "Avg Train Loss: 0.49184764087200167, Avg Train Acc: 0.7862000000476838 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.41825113493949173, Avg Val Acc: 0.886533334851265 (Best: 0.9365333372354507)\n",
      "=== Epoch: 29 ===\n",
      "Avg Train Loss: 0.505438931286335, Avg Train Acc: 0.7840000009536743 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4264418049529195, Avg Val Acc: 0.8953333377838135 (Best: 0.9365333372354507)\n",
      "=== Epoch: 30 ===\n",
      "Avg Train Loss: 0.4820851866900921, Avg Train Acc: 0.7951999998092651 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.43773337656632066, Avg Val Acc: 0.8846666699647904 (Best: 0.9365333372354507)\n",
      "=== Epoch: 31 ===\n",
      "Avg Train Loss: 0.4727924579381943, Avg Train Acc: 0.7928000003099441 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.46586869962513444, Avg Val Acc: 0.8822666680812836 (Best: 0.9365333372354507)\n",
      "=== Epoch: 32 ===\n",
      "Avg Train Loss: 0.5105972947180271, Avg Train Acc: 0.7842999994754791 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3667948939464986, Avg Val Acc: 0.8926666730642319 (Best: 0.9365333372354507)\n",
      "=== Epoch: 33 ===\n",
      "Avg Train Loss: 0.5042687679827214, Avg Train Acc: 0.7838999998569488 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3374420543760061, Avg Val Acc: 0.8996000021696091 (Best: 0.9365333372354507)\n",
      "=== Epoch: 34 ===\n",
      "Avg Train Loss: 0.49693489164113996, Avg Train Acc: 0.7876999986171722 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.42064633321017025, Avg Val Acc: 0.8892000031471252 (Best: 0.9365333372354507)\n",
      "=== Epoch: 35 ===\n",
      "Avg Train Loss: 0.49837010968476536, Avg Train Acc: 0.7899999994039536 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.38783412487246094, Avg Val Acc: 0.8942666667699813 (Best: 0.9365333372354507)\n",
      "=== Epoch: 36 ===\n",
      "Avg Train Loss: 0.4806644620746374, Avg Train Acc: 0.7899000018835067 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.42188763968646525, Avg Val Acc: 0.8776000022888184 (Best: 0.9365333372354507)\n",
      "=== Epoch: 37 ===\n",
      "Avg Train Loss: 0.4786499798297882, Avg Train Acc: 0.7959999984502792 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3613850549608469, Avg Val Acc: 0.8906666678190232 (Best: 0.9365333372354507)\n",
      "=== Epoch: 38 ===\n",
      "Avg Train Loss: 0.48220445290207864, Avg Train Acc: 0.7951999986171723 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.39393106892704965, Avg Val Acc: 0.8902666705846787 (Best: 0.9365333372354507)\n",
      "=== Epoch: 39 ===\n",
      "Avg Train Loss: 0.43773521572351454, Avg Train Acc: 0.8096999949216843 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4479344433173537, Avg Val Acc: 0.8789333349466324 (Best: 0.9365333372354507)\n",
      "=== Epoch: 40 ===\n",
      "Avg Train Loss: 0.4768600434064865, Avg Train Acc: 0.7956999987363815 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.46149629073217513, Avg Val Acc: 0.8878666698932648 (Best: 0.9365333372354507)\n",
      "=== Epoch: 41 ===\n",
      "Avg Train Loss: 0.4564246201515198, Avg Train Acc: 0.8118999963998794 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4541547456383705, Avg Val Acc: 0.8846666699647904 (Best: 0.9365333372354507)\n",
      "=== Epoch: 42 ===\n",
      "Avg Train Loss: 0.40839706763625144, Avg Train Acc: 0.8221000003814697 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4463731287047267, Avg Val Acc: 0.8924000012874603 (Best: 0.9365333372354507)\n",
      "=== Epoch: 43 ===\n",
      "Avg Train Loss: 0.43863824672997, Avg Train Acc: 0.8095999991893769 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4532118175365031, Avg Val Acc: 0.880933336019516 (Best: 0.9365333372354507)\n",
      "=== Epoch: 44 ===\n",
      "Avg Train Loss: 0.4488618138432503, Avg Train Acc: 0.806399998664856 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4485171270370483, Avg Val Acc: 0.8877333372831344 (Best: 0.9365333372354507)\n",
      "=== Epoch: 45 ===\n",
      "Avg Train Loss: 0.44447421297430995, Avg Train Acc: 0.8116000002622604 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.44338273532688616, Avg Val Acc: 0.8789333349466324 (Best: 0.9365333372354507)\n",
      "=== Epoch: 46 ===\n",
      "Avg Train Loss: 0.433104440420866, Avg Train Acc: 0.8165999966859817 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3682452055439353, Avg Val Acc: 0.906000002026558 (Best: 0.9365333372354507)\n",
      "=== Epoch: 47 ===\n",
      "Avg Train Loss: 0.43540310755372047, Avg Train Acc: 0.8203000015020371 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4449812045507133, Avg Val Acc: 0.8866666692495346 (Best: 0.9365333372354507)\n",
      "=== Epoch: 48 ===\n",
      "Avg Train Loss: 0.4193542239814997, Avg Train Acc: 0.8225999987125396 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.44814397136680784, Avg Val Acc: 0.8998666697740555 (Best: 0.9365333372354507)\n",
      "=== Epoch: 49 ===\n",
      "Avg Train Loss: 0.4582312588393688, Avg Train Acc: 0.8099000024795532 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3304328100243583, Avg Val Acc: 0.9092000049352645 (Best: 0.9365333372354507)\n",
      "=== Epoch: 50 ===\n",
      "Avg Train Loss: 0.46273534938693045, Avg Train Acc: 0.8069999969005585 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.41214429336600006, Avg Val Acc: 0.9000000035762787 (Best: 0.9365333372354507)\n",
      "=== Epoch: 51 ===\n",
      "Avg Train Loss: 0.44493575870990754, Avg Train Acc: 0.8137000006437302 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.42399195636622605, Avg Val Acc: 0.8938666677474976 (Best: 0.9365333372354507)\n",
      "=== Epoch: 52 ===\n",
      "Avg Train Loss: 0.4414972164109349, Avg Train Acc: 0.816000000834465 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4389845157042146, Avg Val Acc: 0.8812000030279159 (Best: 0.9365333372354507)\n",
      "=== Epoch: 53 ===\n",
      "Avg Train Loss: 0.43706641137599944, Avg Train Acc: 0.8121000003814697 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3922703503444791, Avg Val Acc: 0.902133337855339 (Best: 0.9365333372354507)\n",
      "=== Epoch: 54 ===\n",
      "Avg Train Loss: 0.4432351475581527, Avg Train Acc: 0.8130000001192093 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3739955349266529, Avg Val Acc: 0.8930666720867158 (Best: 0.9365333372354507)\n",
      "=== Epoch: 55 ===\n",
      "Avg Train Loss: 0.41909092500805856, Avg Train Acc: 0.8166999965906143 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4820219854265451, Avg Val Acc: 0.8801333355903626 (Best: 0.9365333372354507)\n",
      "=== Epoch: 56 ===\n",
      "Avg Train Loss: 0.4641339707560837, Avg Train Acc: 0.8027999985218048 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4259607764147222, Avg Val Acc: 0.88253333568573 (Best: 0.9365333372354507)\n",
      "=== Epoch: 57 ===\n",
      "Avg Train Loss: 0.43388681165874005, Avg Train Acc: 0.8193000000715256 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.43334719602018595, Avg Val Acc: 0.8988000011444092 (Best: 0.9365333372354507)\n",
      "=== Epoch: 58 ===\n",
      "Avg Train Loss: 0.4310271522402763, Avg Train Acc: 0.8135999983549118 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3756385872885585, Avg Val Acc: 0.8934666693210602 (Best: 0.9365333372354507)\n",
      "=== Epoch: 59 ===\n",
      "Avg Train Loss: 0.4487158551067114, Avg Train Acc: 0.8074000000953674 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3709937787242234, Avg Val Acc: 0.8989333379268646 (Best: 0.9365333372354507)\n",
      "=== Epoch: 60 ===\n",
      "Avg Train Loss: 0.44346271589398384, Avg Train Acc: 0.8120999997854232 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4683006171323359, Avg Val Acc: 0.8729333382844925 (Best: 0.9365333372354507)\n",
      "=== Epoch: 61 ===\n",
      "Avg Train Loss: 0.42753030844032763, Avg Train Acc: 0.8151000040769577 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.45197561765089633, Avg Val Acc: 0.889066670536995 (Best: 0.9365333372354507)\n",
      "=== Epoch: 62 ===\n",
      "Avg Train Loss: 0.4039381164498627, Avg Train Acc: 0.8243000000715256 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4310378156229854, Avg Val Acc: 0.8932000011205673 (Best: 0.9365333372354507)\n",
      "=== Epoch: 63 ===\n",
      "Avg Train Loss: 0.41689459009096025, Avg Train Acc: 0.8221999996900559 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4218644120823592, Avg Val Acc: 0.8904000008106232 (Best: 0.9365333372354507)\n",
      "=== Epoch: 64 ===\n",
      "Avg Train Loss: 0.4235454860702157, Avg Train Acc: 0.8170999991893768 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4732958481274545, Avg Val Acc: 0.8900000047683716 (Best: 0.9365333372354507)\n",
      "=== Epoch: 65 ===\n",
      "Avg Train Loss: 0.4561114187538624, Avg Train Acc: 0.8119000005722046 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.39217888412065804, Avg Val Acc: 0.9042666691541672 (Best: 0.9365333372354507)\n",
      "=== Epoch: 66 ===\n",
      "Avg Train Loss: 0.43341859221458434, Avg Train Acc: 0.8179999971389771 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.43698198205791416, Avg Val Acc: 0.893866673707962 (Best: 0.9365333372354507)\n",
      "=== Epoch: 67 ===\n",
      "Avg Train Loss: 0.4203607458993793, Avg Train Acc: 0.8194999998807907 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4827484953217208, Avg Val Acc: 0.8928000038862228 (Best: 0.9365333372354507)\n",
      "=== Epoch: 68 ===\n",
      "Avg Train Loss: 0.41287126116454603, Avg Train Acc: 0.8175999987125396 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4727043534256518, Avg Val Acc: 0.8970666652917862 (Best: 0.9365333372354507)\n",
      "=== Epoch: 69 ===\n",
      "Avg Train Loss: 0.4454510776698589, Avg Train Acc: 0.8087000000476837 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.40860240378417073, Avg Val Acc: 0.8953333336114884 (Best: 0.9365333372354507)\n",
      "=== Epoch: 70 ===\n",
      "Avg Train Loss: 0.42571708928793667, Avg Train Acc: 0.816599999666214 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3717425411194563, Avg Val Acc: 0.8966666698455811 (Best: 0.9365333372354507)\n",
      "=== Epoch: 71 ===\n",
      "Avg Train Loss: 0.43148798257112503, Avg Train Acc: 0.8107999986410142 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.49010783130303026, Avg Val Acc: 0.8866666680574418 (Best: 0.9365333372354507)\n",
      "=== Epoch: 72 ===\n",
      "Avg Train Loss: 0.44667800329625607, Avg Train Acc: 0.8079000002145768 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.442811659835279, Avg Val Acc: 0.8885333353281021 (Best: 0.9365333372354507)\n",
      "=== Epoch: 73 ===\n",
      "Avg Train Loss: 0.4097731948643923, Avg Train Acc: 0.8254000014066696 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.44381773672997954, Avg Val Acc: 0.8997333347797394 (Best: 0.9365333372354507)\n",
      "=== Epoch: 74 ===\n",
      "Avg Train Loss: 0.42646862924098966, Avg Train Acc: 0.8161999982595444 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4840625961124897, Avg Val Acc: 0.8946666675806045 (Best: 0.9365333372354507)\n",
      "=== Epoch: 75 ===\n",
      "Avg Train Loss: 0.43452794454991817, Avg Train Acc: 0.8141999983787537 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.38966011825948954, Avg Val Acc: 0.9028000050783157 (Best: 0.9365333372354507)\n",
      "=== Epoch: 76 ===\n",
      "Avg Train Loss: 0.4048903748393059, Avg Train Acc: 0.8248999971151352 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4434206999931484, Avg Val Acc: 0.8849333369731903 (Best: 0.9365333372354507)\n",
      "=== Epoch: 77 ===\n",
      "Avg Train Loss: 0.42553104102611544, Avg Train Acc: 0.8172000014781952 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.41010380173102023, Avg Val Acc: 0.902666671872139 (Best: 0.9365333372354507)\n",
      "=== Epoch: 78 ===\n",
      "Avg Train Loss: 0.4265503159770742, Avg Train Acc: 0.8155999982357025 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3658125833235681, Avg Val Acc: 0.8969333350658417 (Best: 0.9365333372354507)\n",
      "=== Epoch: 79 ===\n",
      "Avg Train Loss: 0.39506065655499695, Avg Train Acc: 0.8298000049591064 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.459929143153131, Avg Val Acc: 0.8878666675090789 (Best: 0.9365333372354507)\n",
      "=== Epoch: 80 ===\n",
      "Avg Train Loss: 0.41415899198502304, Avg Train Acc: 0.8218999999761581 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.533146040160209, Avg Val Acc: 0.8729333341121673 (Best: 0.9365333372354507)\n",
      "=== Epoch: 81 ===\n",
      "Avg Train Loss: 0.410003662686795, Avg Train Acc: 0.820100000500679 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4146532806195319, Avg Val Acc: 0.8922666746377945 (Best: 0.9365333372354507)\n",
      "=== Epoch: 82 ===\n",
      "Avg Train Loss: 0.4274320982396603, Avg Train Acc: 0.8173999977111817 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4725766565278173, Avg Val Acc: 0.8853333353996277 (Best: 0.9365333372354507)\n",
      "=== Epoch: 83 ===\n",
      "Avg Train Loss: 0.4336001542955637, Avg Train Acc: 0.8136999988555909 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4365747101511806, Avg Val Acc: 0.8874666702747345 (Best: 0.9365333372354507)\n",
      "=== Epoch: 84 ===\n",
      "Avg Train Loss: 0.4186662565171719, Avg Train Acc: 0.8225000005960464 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.46657760174013674, Avg Val Acc: 0.8906666702032089 (Best: 0.9365333372354507)\n",
      "=== Epoch: 85 ===\n",
      "Avg Train Loss: 0.4223833554983139, Avg Train Acc: 0.8188999962806701 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.5240805337391794, Avg Val Acc: 0.8952000057697296 (Best: 0.9365333372354507)\n",
      "=== Epoch: 86 ===\n",
      "Avg Train Loss: 0.40496015682816505, Avg Train Acc: 0.8239999985694886 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4217028649896383, Avg Val Acc: 0.8993333381414413 (Best: 0.9365333372354507)\n",
      "=== Epoch: 87 ===\n",
      "Avg Train Loss: 0.44429847955703733, Avg Train Acc: 0.8119000017642974 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.508826185837388, Avg Val Acc: 0.8664000022411347 (Best: 0.9365333372354507)\n",
      "=== Epoch: 88 ===\n",
      "Avg Train Loss: 0.45480398401618005, Avg Train Acc: 0.8085000026226044 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.3919339098781347, Avg Val Acc: 0.8994666689634323 (Best: 0.9365333372354507)\n",
      "=== Epoch: 89 ===\n",
      "Avg Train Loss: 0.40456809364259244, Avg Train Acc: 0.8256999969482421 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.42666408397257327, Avg Val Acc: 0.898800002336502 (Best: 0.9365333372354507)\n",
      "=== Epoch: 90 ===\n",
      "Avg Train Loss: 0.4452022092044354, Avg Train Acc: 0.8094999986886978 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.5584250487200916, Avg Val Acc: 0.8837333369255066 (Best: 0.9365333372354507)\n",
      "=== Epoch: 91 ===\n",
      "Avg Train Loss: 0.40377315107733014, Avg Train Acc: 0.8296000003814697 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.406066454090178, Avg Val Acc: 0.8946666723489761 (Best: 0.9365333372354507)\n",
      "=== Epoch: 92 ===\n",
      "Avg Train Loss: 0.4355875089764595, Avg Train Acc: 0.8132999992370605 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.5261424011923372, Avg Val Acc: 0.8856000047922135 (Best: 0.9365333372354507)\n",
      "=== Epoch: 93 ===\n",
      "Avg Train Loss: 0.4130269268900156, Avg Train Acc: 0.8244000011682511 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.487782639618963, Avg Val Acc: 0.8775999999046326 (Best: 0.9365333372354507)\n",
      "=== Epoch: 94 ===\n",
      "Avg Train Loss: 0.4074408156424761, Avg Train Acc: 0.8293999999761581 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.5300403615832329, Avg Val Acc: 0.8732000041007996 (Best: 0.9365333372354507)\n",
      "=== Epoch: 95 ===\n",
      "Avg Train Loss: 0.42009691536426547, Avg Train Acc: 0.8168000012636185 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4456731730513275, Avg Val Acc: 0.8866666698455811 (Best: 0.9365333372354507)\n",
      "=== Epoch: 96 ===\n",
      "Avg Train Loss: 0.4038380560837686, Avg Train Acc: 0.8272999989986419 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.5148475434724241, Avg Val Acc: 0.8940000033378601 (Best: 0.9365333372354507)\n",
      "=== Epoch: 97 ===\n",
      "Avg Train Loss: 0.3854881351441145, Avg Train Acc: 0.8345000004768371 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4097193293273449, Avg Val Acc: 0.8941333347558975 (Best: 0.9365333372354507)\n",
      "=== Epoch: 98 ===\n",
      "Avg Train Loss: 0.4355333811789751, Avg Train Acc: 0.8125999975204468 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.4286671813391149, Avg Val Acc: 0.8933333367109298 (Best: 0.9365333372354507)\n",
      "=== Epoch: 99 ===\n",
      "Avg Train Loss: 0.417702856734395, Avg Train Acc: 0.8201999986171722 (Best: 0.9365333372354507)\n",
      "Avg Val Loss: 0.5322247041575611, Avg Val Acc: 0.8801333379745483 (Best: 0.9365333372354507)\n"
     ]
    }
   ],
   "source": [
    "if detector.train:\n",
    "    detector.trainModel(train_X=train_X, train_Y = train_y, val_X=val_X, val_Y=val_y, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.8304933373034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8304933373034"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.testModel(test_X=test_X, test_Y=test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning\n",
    "\n",
    "X = test_X\n",
    "y = test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import combinations\n",
    "\n",
    "def run_experiment(X, y, n_experiments=100):\n",
    "    classes = np.unique(y)\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    for _ in range(n_experiments):\n",
    "        # 隨機選擇5個類別\n",
    "        selected_classes = np.random.choice(classes, 5, replace=False)\n",
    "        \n",
    "        train_indices = []\n",
    "        test_indices = []\n",
    "        \n",
    "        for cls in selected_classes:\n",
    "            cls_indices = np.where(y == cls)[0]\n",
    "            train_indices.extend(np.random.choice(cls_indices, 5, replace=False))\n",
    "            test_indices.extend([idx for idx in cls_indices if idx not in train_indices])\n",
    "\n",
    "        X_train, y_train = X[train_indices], y[train_indices]\n",
    "        X_test, y_test = X[test_indices], y[test_indices]\n",
    "\n",
    "        # 訓練SVM\n",
    "        svm = SVC(kernel='rbf', gamma='scale')\n",
    "        svm.fit(X_train, y_train)\n",
    "        \n",
    "        # 預測並計算準確率\n",
    "        y_pred = svm.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    return np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 5-way 5-shot accuracy: 0.8801\n"
     ]
    }
   ],
   "source": [
    "avg_accuracy = run_experiment(X, y)\n",
    "print(f\"Average 5-way 5-shot accuracy: {avg_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byteSequence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
