{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all datasets...\n",
      "train dataset shape: (820, 14)\n",
      "train dataset family number: 41\n",
      "test dataset shape: (300, 14)\n",
      "test dataset family number: 15\n",
      "val dataset shape: (100, 14)\n",
      "val dataset family number: 5\n",
      "Vectorizing byte sequence using TF-IDF.\n"
     ]
    }
   ],
   "source": [
    "from malwareDetector import malwareDetector\n",
    "from dataLoader import DatasetLoad\n",
    "from byteSequenceVectorize import ByteSequenceVectorizer\n",
    "\n",
    "detector = malwareDetector(cluster=False, train=True, val=True, cpuArch=\"i386_x86_64Label\",\n",
    "                            support_shots=5, query_shots=5, class_per_iter=None, class_per_iter_test=5,\n",
    "                            loss=\"nn_prototypical\", dropout_prob=0.5, splitByCpu=True)\n",
    "\n",
    "dataset = DatasetLoad(detector)\n",
    "\n",
    "vectorize = ByteSequenceVectorizer(method = \"tfidf\", detector = detector, dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorize Method:  tfidf\n",
      "Loading vectorized byte sequence from ./embedding...\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorize Method: \", vectorize.vectorize_method)\n",
    "featureDim = 1000\n",
    "n_gramRange = (2, 4)\n",
    "\n",
    "train_X, test_X, val_X, train_y, test_y, val_y, train_map, test_map, val_map = vectorize.vectorize_func(featureDim, n_gramRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape:  (820, 1000) <class 'numpy.ndarray'>\n",
      "Train y shape:  (820,) <class 'numpy.ndarray'>\n",
      "Test X shape:  (300, 1000)\n",
      "Test y shape:  (300,)\n",
      "Val X shape:  (100, 1000)\n",
      "Val y shape:  (100,)\n",
      "Train Map:  {0: 'aenjaris_Advanced Micro Devices X86-64', 1: 'blueshell_Advanced Micro Devices X86-64', 2: 'bpfdoor_Advanced Micro Devices X86-64', 3: 'camelot_Advanced Micro Devices X86-64', 4: 'chisel_Advanced Micro Devices X86-64', 5: 'cleanlog_Advanced Micro Devices X86-64', 6: 'cobaltstrike_Advanced Micro Devices X86-64', 7: 'cryptonote_Advanced Micro Devices X86-64', 8: 'dnsamp_Advanced Micro Devices X86-64', 9: 'dnscat_Advanced Micro Devices X86-64', 10: 'dropperl_Advanced Micro Devices X86-64', 11: 'drtycow_Advanced Micro Devices X86-64', 12: 'exploitscan_Advanced Micro Devices X86-64', 13: 'ezuriloader_Advanced Micro Devices X86-64', 14: 'fritzfrog_Advanced Micro Devices X86-64', 15: 'fscan_Advanced Micro Devices X86-64', 16: 'gafgyt_Advanced Micro Devices X86-64', 17: 'hive_Advanced Micro Devices X86-64', 18: 'horsepill_Advanced Micro Devices X86-64', 19: 'kaiji_Advanced Micro Devices X86-64', 20: 'lady_Advanced Micro Devices X86-64', 21: 'malsource_Advanced Micro Devices X86-64', 22: 'malxmr_Advanced Micro Devices X86-64', 23: 'merlin_Advanced Micro Devices X86-64', 24: 'meterpreter_Advanced Micro Devices X86-64', 25: 'mirai_Advanced Micro Devices X86-64', 26: 'pnscan_Advanced Micro Devices X86-64', 27: 'poseidon_Advanced Micro Devices X86-64', 28: 'prochider_Advanced Micro Devices X86-64', 29: 'psybnc_Advanced Micro Devices X86-64', 30: 'rekoobe_Advanced Micro Devices X86-64', 31: 'reversessh_Advanced Micro Devices X86-64', 32: 'revproxy_Advanced Micro Devices X86-64', 33: 'sliver_Advanced Micro Devices X86-64', 34: 'sshdoor_Advanced Micro Devices X86-64', 35: 'stowaway_Advanced Micro Devices X86-64', 36: 'tsunami_Advanced Micro Devices X86-64', 37: 'vtflooder_Advanced Micro Devices X86-64', 38: 'winexe_Advanced Micro Devices X86-64', 39: 'winnti_Advanced Micro Devices X86-64', 40: 'xmrig_Advanced Micro Devices X86-64'}\n",
      "Test Map:  {0: 'backegmm_Intel 80386', 1: 'cornelgen_Intel 80386', 2: 'dnsamp_Intel 80386', 3: 'gafgyt_Intel 80386', 4: 'kaiji_Intel 80386', 5: 'meterpreter_Intel 80386', 6: 'mirai_Intel 80386', 7: 'pnscan_Intel 80386', 8: 'prochider_Intel 80386', 9: 'rkit_Intel 80386', 10: 'sckit_Intel 80386', 11: 'sshbrute_Intel 80386', 12: 'sshdoor_Intel 80386', 13: 'tsunami_Intel 80386', 14: 'xorddos_Intel 80386'}\n",
      "Val Map:  {0: 'equationdrug_Intel 80386', 1: 'exploitscan_Intel 80386', 2: 'local_Intel 80386', 3: 'race_Intel 80386', 4: 'sliver_Intel 80386'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train X shape: \", train_X.shape, type(train_X))\n",
    "print(\"Train y shape: \", train_y.shape, type(train_y))\n",
    "print(\"Test X shape: \", test_X.shape)\n",
    "print(\"Test y shape: \", test_y.shape)\n",
    "if(val_X is not None):\n",
    "    print(\"Val X shape: \", val_X.shape)\n",
    "    print(\"Val y shape: \", val_y.shape)\n",
    "print(\"Train Map: \", train_map)\n",
    "print(\"Test Map: \", test_map)\n",
    "if(val_map is not None):\n",
    "    print(\"Val Map: \", val_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes per iteration: 41\n",
      "N-shot: 5\n",
      "=== Epoch: 0 ===\n",
      "Avg Train Loss: 2.4187961399555205, Avg Train Acc: 0.27121951125562194 (Best)\n",
      "Avg Val Loss: 0.9189046972990036, Avg Val Acc: 0.684666665494442 (Best)\n",
      "Model saved at ./model/model_i386_x86_64Label_nn_prototypical_splitByCpu_withVal.pt\n",
      "=== Epoch: 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mandy900619/anaconda3/envs/smell/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 1.5681384122371673, Avg Train Acc: 0.5010731706023216 (Best: 0.684666665494442)\n",
      "Avg Val Loss: 0.8372884929180145, Avg Val Acc: 0.7161333340406418 (Best)\n",
      "Model saved at ./model/model_i386_x86_64Label_nn_prototypical_splitByCpu_withVal.pt\n",
      "=== Epoch: 2 ===\n",
      "Avg Train Loss: 1.3048669850826264, Avg Train Acc: 0.5807317084074021 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 0.8459504091739655, Avg Val Acc: 0.7066666680574417 (Best: 0.7161333340406418)\n",
      "=== Epoch: 3 ===\n",
      "Avg Train Loss: 1.2037632966041565, Avg Train Acc: 0.6094146341085434 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 0.8833000409603119, Avg Val Acc: 0.7016000038385392 (Best: 0.7161333340406418)\n",
      "=== Epoch: 4 ===\n",
      "Avg Train Loss: 1.1510614895820617, Avg Train Acc: 0.6258536595106124 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 0.9304292702674866, Avg Val Acc: 0.6960000002384186 (Best: 0.7161333340406418)\n",
      "=== Epoch: 5 ===\n",
      "Avg Train Loss: 1.121403727531433, Avg Train Acc: 0.6402439004182816 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 0.9446410584449768, Avg Val Acc: 0.6852000027894973 (Best: 0.7161333340406418)\n",
      "=== Epoch: 6 ===\n",
      "Avg Train Loss: 1.0820098841190338, Avg Train Acc: 0.6492195099592208 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0448825180530548, Avg Val Acc: 0.6744000005722046 (Best: 0.7161333340406418)\n",
      "=== Epoch: 7 ===\n",
      "Avg Train Loss: 1.0803486180305482, Avg Train Acc: 0.6505853629112244 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0235323530435563, Avg Val Acc: 0.6684000024199486 (Best: 0.7161333340406418)\n",
      "=== Epoch: 8 ===\n",
      "Avg Train Loss: 1.0666112917661668, Avg Train Acc: 0.6560487800836563 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.029527531862259, Avg Val Acc: 0.6661333334445954 (Best: 0.7161333340406418)\n",
      "=== Epoch: 9 ===\n",
      "Avg Train Loss: 1.0474442154169084, Avg Train Acc: 0.6578536558151246 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0728258091211318, Avg Val Acc: 0.6736000007390976 (Best: 0.7161333340406418)\n",
      "=== Epoch: 10 ===\n",
      "Avg Train Loss: 1.044061421751976, Avg Train Acc: 0.6623902463912964 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.119182016849518, Avg Val Acc: 0.6708000010251999 (Best: 0.7161333340406418)\n",
      "=== Epoch: 11 ===\n",
      "Avg Train Loss: 1.0321498775482179, Avg Train Acc: 0.6649268335103988 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1723377287387848, Avg Val Acc: 0.6333333319425583 (Best: 0.7161333340406418)\n",
      "=== Epoch: 12 ===\n",
      "Avg Train Loss: 1.0232344871759416, Avg Train Acc: 0.6645365917682647 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.122945185303688, Avg Val Acc: 0.6343999966979027 (Best: 0.7161333340406418)\n",
      "=== Epoch: 13 ===\n",
      "Avg Train Loss: 1.0270193541049957, Avg Train Acc: 0.6666829311847686 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1007665860652924, Avg Val Acc: 0.6495999997854233 (Best: 0.7161333340406418)\n",
      "=== Epoch: 14 ===\n",
      "Avg Train Loss: 1.0142721492052078, Avg Train Acc: 0.666000002026558 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.161767639517784, Avg Val Acc: 0.6067999976873398 (Best: 0.7161333340406418)\n",
      "=== Epoch: 15 ===\n",
      "Avg Train Loss: 1.0086457049846649, Avg Train Acc: 0.6699024432897568 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0350967705249787, Avg Val Acc: 0.6558666676282883 (Best: 0.7161333340406418)\n",
      "=== Epoch: 16 ===\n",
      "Avg Train Loss: 1.003974934220314, Avg Train Acc: 0.6744390261173249 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1037498319149017, Avg Val Acc: 0.6591999965906143 (Best: 0.7161333340406418)\n",
      "=== Epoch: 17 ===\n",
      "Avg Train Loss: 1.0001051533222198, Avg Train Acc: 0.6748292750120163 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0530769366025925, Avg Val Acc: 0.6701333343982696 (Best: 0.7161333340406418)\n",
      "=== Epoch: 18 ===\n",
      "Avg Train Loss: 1.010254008769989, Avg Train Acc: 0.6723414695262909 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1074177944660186, Avg Val Acc: 0.6445333302021027 (Best: 0.7161333340406418)\n",
      "=== Epoch: 19 ===\n",
      "Avg Train Loss: 0.9989871567487717, Avg Train Acc: 0.6756585413217544 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0539388567209245, Avg Val Acc: 0.6515999984741211 (Best: 0.7161333340406418)\n",
      "=== Epoch: 20 ===\n",
      "Avg Train Loss: 1.001930948495865, Avg Train Acc: 0.6749268335103988 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.058444122672081, Avg Val Acc: 0.6533333325386047 (Best: 0.7161333340406418)\n",
      "=== Epoch: 21 ===\n",
      "Avg Train Loss: 0.988788275718689, Avg Train Acc: 0.6749756127595902 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0668612158298492, Avg Val Acc: 0.6545333322882653 (Best: 0.7161333340406418)\n",
      "=== Epoch: 22 ===\n",
      "Avg Train Loss: 0.9874377739429474, Avg Train Acc: 0.6769756132364273 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0553278064727782, Avg Val Acc: 0.6566666686534881 (Best: 0.7161333340406418)\n",
      "=== Epoch: 23 ===\n",
      "Avg Train Loss: 0.9828039133548736, Avg Train Acc: 0.6794146358966827 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.063286882042885, Avg Val Acc: 0.6740000027418137 (Best: 0.7161333340406418)\n",
      "=== Epoch: 24 ===\n",
      "Avg Train Loss: 0.979738114476204, Avg Train Acc: 0.6802439051866531 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1161090928316115, Avg Val Acc: 0.638933333158493 (Best: 0.7161333340406418)\n",
      "=== Epoch: 25 ===\n",
      "Avg Train Loss: 0.9730690497159958, Avg Train Acc: 0.6811219555139542 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.109170108437538, Avg Val Acc: 0.6293333345651626 (Best: 0.7161333340406418)\n",
      "=== Epoch: 26 ===\n",
      "Avg Train Loss: 0.9745556330680847, Avg Train Acc: 0.6793658584356308 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.094983584880829, Avg Val Acc: 0.637333333492279 (Best: 0.7161333340406418)\n",
      "=== Epoch: 27 ===\n",
      "Avg Train Loss: 0.9793524843454361, Avg Train Acc: 0.6818048810958862 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0750104784965515, Avg Val Acc: 0.6434666651487351 (Best: 0.7161333340406418)\n",
      "=== Epoch: 28 ===\n",
      "Avg Train Loss: 0.9800397646427155, Avg Train Acc: 0.6799024426937104 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0688169533014298, Avg Val Acc: 0.6381333336234093 (Best: 0.7161333340406418)\n",
      "=== Epoch: 29 ===\n",
      "Avg Train Loss: 0.9660036504268646, Avg Train Acc: 0.6858048790693283 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0515046763420104, Avg Val Acc: 0.6631999987363816 (Best: 0.7161333340406418)\n",
      "=== Epoch: 30 ===\n",
      "Avg Train Loss: 0.9720738673210144, Avg Train Acc: 0.68239024579525 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1211918431520462, Avg Val Acc: 0.6457333326339721 (Best: 0.7161333340406418)\n",
      "=== Epoch: 31 ===\n",
      "Avg Train Loss: 0.9713887166976929, Avg Train Acc: 0.6803902471065522 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.094173822402954, Avg Val Acc: 0.6469333326816559 (Best: 0.7161333340406418)\n",
      "=== Epoch: 32 ===\n",
      "Avg Train Loss: 0.9619476294517517, Avg Train Acc: 0.6853658545017243 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1107462382316589, Avg Val Acc: 0.6390666657686234 (Best: 0.7161333340406418)\n",
      "=== Epoch: 33 ===\n",
      "Avg Train Loss: 0.9673227733373642, Avg Train Acc: 0.6837560999393463 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1834092062711716, Avg Val Acc: 0.6578666681051254 (Best: 0.7161333340406418)\n",
      "=== Epoch: 34 ===\n",
      "Avg Train Loss: 0.9649892616271972, Avg Train Acc: 0.6880975610017777 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1509593093395234, Avg Val Acc: 0.6754666662216187 (Best: 0.7161333340406418)\n",
      "=== Epoch: 35 ===\n",
      "Avg Train Loss: 0.9566944396495819, Avg Train Acc: 0.6882926815748215 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0407518792152404, Avg Val Acc: 0.6624000006914139 (Best: 0.7161333340406418)\n",
      "=== Epoch: 36 ===\n",
      "Avg Train Loss: 0.9609996318817139, Avg Train Acc: 0.6876585358381271 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0898488056659699, Avg Val Acc: 0.6538666671514511 (Best: 0.7161333340406418)\n",
      "=== Epoch: 37 ===\n",
      "Avg Train Loss: 0.9573224502801895, Avg Train Acc: 0.6877073162794113 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1351198041439057, Avg Val Acc: 0.6599999991059303 (Best: 0.7161333340406418)\n",
      "=== Epoch: 38 ===\n",
      "Avg Train Loss: 0.9586059147119522, Avg Train Acc: 0.6866341471672058 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.100829643011093, Avg Val Acc: 0.6614666670560837 (Best: 0.7161333340406418)\n",
      "=== Epoch: 39 ===\n",
      "Avg Train Loss: 0.9669773161411286, Avg Train Acc: 0.685560976266861 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1656506526470185, Avg Val Acc: 0.6554666662216186 (Best: 0.7161333340406418)\n",
      "=== Epoch: 40 ===\n",
      "Avg Train Loss: 0.9530969291925431, Avg Train Acc: 0.6879024362564087 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1246626979112626, Avg Val Acc: 0.6665333330631256 (Best: 0.7161333340406418)\n",
      "=== Epoch: 41 ===\n",
      "Avg Train Loss: 0.9479748725891113, Avg Train Acc: 0.6900975584983826 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1332251614332198, Avg Val Acc: 0.673466666340828 (Best: 0.7161333340406418)\n",
      "=== Epoch: 42 ===\n",
      "Avg Train Loss: 0.9536869108676911, Avg Train Acc: 0.6870243901014328 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1711388200521469, Avg Val Acc: 0.6473333323001862 (Best: 0.7161333340406418)\n",
      "=== Epoch: 43 ===\n",
      "Avg Train Loss: 0.9499047255516052, Avg Train Acc: 0.6899512189626694 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.2184722512960433, Avg Val Acc: 0.6386666655540466 (Best: 0.7161333340406418)\n",
      "=== Epoch: 44 ===\n",
      "Avg Train Loss: 0.9424402195215226, Avg Train Acc: 0.6907317036390305 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1575491124391555, Avg Val Acc: 0.6598666661977768 (Best: 0.7161333340406418)\n",
      "=== Epoch: 45 ===\n",
      "Avg Train Loss: 0.9517282992601395, Avg Train Acc: 0.6893170726299286 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.196053095459938, Avg Val Acc: 0.6375999954342843 (Best: 0.7161333340406418)\n",
      "=== Epoch: 46 ===\n",
      "Avg Train Loss: 0.9443745511770248, Avg Train Acc: 0.6905853635072708 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.177187334895134, Avg Val Acc: 0.635733335018158 (Best: 0.7161333340406418)\n",
      "=== Epoch: 47 ===\n",
      "Avg Train Loss: 0.9397418743371964, Avg Train Acc: 0.6906341445446015 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.169898271560669, Avg Val Acc: 0.647466669678688 (Best: 0.7161333340406418)\n",
      "=== Epoch: 48 ===\n",
      "Avg Train Loss: 0.943506196141243, Avg Train Acc: 0.6913170725107193 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1321336913108826, Avg Val Acc: 0.6586666670441628 (Best: 0.7161333340406418)\n",
      "=== Epoch: 49 ===\n",
      "Avg Train Loss: 0.9480193334817887, Avg Train Acc: 0.6873170721530915 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.166147491335869, Avg Val Acc: 0.6330666655302047 (Best: 0.7161333340406418)\n",
      "=== Epoch: 50 ===\n",
      "Avg Train Loss: 0.9446125555038453, Avg Train Acc: 0.6918536585569381 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.085941243171692, Avg Val Acc: 0.6353333359956741 (Best: 0.7161333340406418)\n",
      "=== Epoch: 51 ===\n",
      "Avg Train Loss: 0.9482426625490189, Avg Train Acc: 0.6895121943950653 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0978460258245468, Avg Val Acc: 0.6464000010490417 (Best: 0.7161333340406418)\n",
      "=== Epoch: 52 ===\n",
      "Avg Train Loss: 0.9393017506599426, Avg Train Acc: 0.6899999958276749 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.2480942964553834, Avg Val Acc: 0.6309333336353302 (Best: 0.7161333340406418)\n",
      "=== Epoch: 53 ===\n",
      "Avg Train Loss: 0.9437294536828995, Avg Train Acc: 0.6872682934999466 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.2057963252067565, Avg Val Acc: 0.6306666651368141 (Best: 0.7161333340406418)\n",
      "=== Epoch: 54 ===\n",
      "Avg Train Loss: 0.9403121435642242, Avg Train Acc: 0.6913658529520035 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1236084640026092, Avg Val Acc: 0.6462666669487953 (Best: 0.7161333340406418)\n",
      "=== Epoch: 55 ===\n",
      "Avg Train Loss: 0.9428741759061814, Avg Train Acc: 0.6910243880748749 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1349079990386963, Avg Val Acc: 0.6550666677951813 (Best: 0.7161333340406418)\n",
      "=== Epoch: 56 ===\n",
      "Avg Train Loss: 0.9526404595375061, Avg Train Acc: 0.6899024373292924 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.164078574180603, Avg Val Acc: 0.655733333826065 (Best: 0.7161333340406418)\n",
      "=== Epoch: 57 ===\n",
      "Avg Train Loss: 0.9430099272727966, Avg Train Acc: 0.6882926833629608 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1471497601270675, Avg Val Acc: 0.678933333158493 (Best: 0.7161333340406418)\n",
      "=== Epoch: 58 ===\n",
      "Avg Train Loss: 0.9348383980989456, Avg Train Acc: 0.6930731672048569 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.2718936717510223, Avg Val Acc: 0.6606666666269302 (Best: 0.7161333340406418)\n",
      "=== Epoch: 59 ===\n",
      "Avg Train Loss: 0.9357693189382553, Avg Train Acc: 0.6917073142528534 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.2708560889959335, Avg Val Acc: 0.6368000000715256 (Best: 0.7161333340406418)\n",
      "=== Epoch: 60 ===\n",
      "Avg Train Loss: 0.9392783147096634, Avg Train Acc: 0.6936585313081741 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1129109632968903, Avg Val Acc: 0.6493333303928375 (Best: 0.7161333340406418)\n",
      "=== Epoch: 61 ===\n",
      "Avg Train Loss: 0.9375466400384903, Avg Train Acc: 0.6930731678009033 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1783924722671508, Avg Val Acc: 0.6146666660904885 (Best: 0.7161333340406418)\n",
      "=== Epoch: 62 ===\n",
      "Avg Train Loss: 0.9332584857940673, Avg Train Acc: 0.6943414616584778 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1531809544563294, Avg Val Acc: 0.648933330476284 (Best: 0.7161333340406418)\n",
      "=== Epoch: 63 ===\n",
      "Avg Train Loss: 0.9370259046554565, Avg Train Acc: 0.6934146320819855 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.112047280073166, Avg Val Acc: 0.6499999982118606 (Best: 0.7161333340406418)\n",
      "=== Epoch: 64 ===\n",
      "Avg Train Loss: 0.935437998175621, Avg Train Acc: 0.6951219463348388 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1286810898780824, Avg Val Acc: 0.6325333327054977 (Best: 0.7161333340406418)\n",
      "=== Epoch: 65 ===\n",
      "Avg Train Loss: 0.933905661702156, Avg Train Acc: 0.6927317065000534 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.084954941868782, Avg Val Acc: 0.6301333314180374 (Best: 0.7161333340406418)\n",
      "=== Epoch: 66 ===\n",
      "Avg Train Loss: 0.9252385485172272, Avg Train Acc: 0.6958048737049103 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0918767070770263, Avg Val Acc: 0.640933333337307 (Best: 0.7161333340406418)\n",
      "=== Epoch: 67 ===\n",
      "Avg Train Loss: 0.9325713193416596, Avg Train Acc: 0.6947804826498032 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1341474789381027, Avg Val Acc: 0.6291999971866608 (Best: 0.7161333340406418)\n",
      "=== Epoch: 68 ===\n",
      "Avg Train Loss: 0.9268716806173325, Avg Train Acc: 0.6946341437101364 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1525813138484955, Avg Val Acc: 0.6205333361029625 (Best: 0.7161333340406418)\n",
      "=== Epoch: 69 ===\n",
      "Avg Train Loss: 0.9242672848701478, Avg Train Acc: 0.6953170698881149 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1505888795852661, Avg Val Acc: 0.6265333315730095 (Best: 0.7161333340406418)\n",
      "=== Epoch: 70 ===\n",
      "Avg Train Loss: 0.9309664982557296, Avg Train Acc: 0.695999995470047 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.131261806488037, Avg Val Acc: 0.5993333303928375 (Best: 0.7161333340406418)\n",
      "=== Epoch: 71 ===\n",
      "Avg Train Loss: 0.9199271494150162, Avg Train Acc: 0.6971707266569137 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1281136912107468, Avg Val Acc: 0.6253333342075348 (Best: 0.7161333340406418)\n",
      "=== Epoch: 72 ===\n",
      "Avg Train Loss: 0.9253240239620208, Avg Train Acc: 0.6965853625535965 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1499835801124574, Avg Val Acc: 0.6046666660904885 (Best: 0.7161333340406418)\n",
      "=== Epoch: 73 ===\n",
      "Avg Train Loss: 0.9168454736471177, Avg Train Acc: 0.7011707288026809 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1380248117446898, Avg Val Acc: 0.6381333330273629 (Best: 0.7161333340406418)\n",
      "=== Epoch: 74 ===\n",
      "Avg Train Loss: 0.91681136906147, Avg Train Acc: 0.6993170660734177 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.071861625313759, Avg Val Acc: 0.6346666669845581 (Best: 0.7161333340406418)\n",
      "=== Epoch: 75 ===\n",
      "Avg Train Loss: 0.9095075505971909, Avg Train Acc: 0.7015609723329544 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1017332834005356, Avg Val Acc: 0.6401333341002464 (Best: 0.7161333340406418)\n",
      "=== Epoch: 76 ===\n",
      "Avg Train Loss: 0.9178149110078812, Avg Train Acc: 0.6975609713792801 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1854655820131301, Avg Val Acc: 0.6435999983549118 (Best: 0.7161333340406418)\n",
      "=== Epoch: 77 ===\n",
      "Avg Train Loss: 0.9103468310832977, Avg Train Acc: 0.6997560942173005 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1585209792852402, Avg Val Acc: 0.6341333317756653 (Best: 0.7161333340406418)\n",
      "=== Epoch: 78 ===\n",
      "Avg Train Loss: 0.91385588824749, Avg Train Acc: 0.7016097521781921 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.2091437381505967, Avg Val Acc: 0.5880000013113021 (Best: 0.7161333340406418)\n",
      "=== Epoch: 79 ===\n",
      "Avg Train Loss: 0.9079676467180252, Avg Train Acc: 0.6984390187263488 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.160541334748268, Avg Val Acc: 0.6349333333969116 (Best: 0.7161333340406418)\n",
      "=== Epoch: 80 ===\n",
      "Avg Train Loss: 0.9076001596450806, Avg Train Acc: 0.7036585319042206 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1580399018526077, Avg Val Acc: 0.6587999987602234 (Best: 0.7161333340406418)\n",
      "=== Epoch: 81 ===\n",
      "Avg Train Loss: 0.912428936958313, Avg Train Acc: 0.7004390192031861 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0687634855508805, Avg Val Acc: 0.6170666685700417 (Best: 0.7161333340406418)\n",
      "=== Epoch: 82 ===\n",
      "Avg Train Loss: 0.9133161389827729, Avg Train Acc: 0.7002926748991013 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.080231938958168, Avg Val Acc: 0.6541333341598511 (Best: 0.7161333340406418)\n",
      "=== Epoch: 83 ===\n",
      "Avg Train Loss: 0.9146091091632843, Avg Train Acc: 0.7017073118686676 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.0494824302196504, Avg Val Acc: 0.6481333339214325 (Best: 0.7161333340406418)\n",
      "=== Epoch: 84 ===\n",
      "Avg Train Loss: 0.9163031029701233, Avg Train Acc: 0.7018048721551895 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.06358717918396, Avg Val Acc: 0.6269333317875863 (Best: 0.7161333340406418)\n",
      "=== Epoch: 85 ===\n",
      "Avg Train Loss: 0.9087461590766907, Avg Train Acc: 0.7025365799665451 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1197599953413009, Avg Val Acc: 0.6330666673183442 (Best: 0.7161333340406418)\n",
      "=== Epoch: 86 ===\n",
      "Avg Train Loss: 0.9090192276239395, Avg Train Acc: 0.7006341397762299 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.164549680352211, Avg Val Acc: 0.6267999976873397 (Best: 0.7161333340406418)\n",
      "=== Epoch: 87 ===\n",
      "Avg Train Loss: 0.8970657795667648, Avg Train Acc: 0.7032195061445237 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1264018732309342, Avg Val Acc: 0.6177333346009255 (Best: 0.7161333340406418)\n",
      "=== Epoch: 88 ===\n",
      "Avg Train Loss: 0.9074687653779984, Avg Train Acc: 0.702829259634018 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1805820661783217, Avg Val Acc: 0.6222666662931442 (Best: 0.7161333340406418)\n",
      "=== Epoch: 89 ===\n",
      "Avg Train Loss: 0.9007160639762879, Avg Train Acc: 0.7015609699487686 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1883403807878494, Avg Val Acc: 0.6114666652679444 (Best: 0.7161333340406418)\n",
      "=== Epoch: 90 ===\n",
      "Avg Train Loss: 0.9066835242509842, Avg Train Acc: 0.7022438967227935 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1758250504732133, Avg Val Acc: 0.6019999963045121 (Best: 0.7161333340406418)\n",
      "=== Epoch: 91 ===\n",
      "Avg Train Loss: 0.8968704569339753, Avg Train Acc: 0.7043414574861526 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.137002345919609, Avg Val Acc: 0.5818666657805442 (Best: 0.7161333340406418)\n",
      "=== Epoch: 92 ===\n",
      "Avg Train Loss: 0.8932441818714142, Avg Train Acc: 0.7032195061445237 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.158425163626671, Avg Val Acc: 0.6269333335757256 (Best: 0.7161333340406418)\n",
      "=== Epoch: 93 ===\n",
      "Avg Train Loss: 0.8982240426540374, Avg Train Acc: 0.7056097501516342 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1769656074047088, Avg Val Acc: 0.6259999984502792 (Best: 0.7161333340406418)\n",
      "=== Epoch: 94 ===\n",
      "Avg Train Loss: 0.8882678055763245, Avg Train Acc: 0.7073658472299575 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.2148977249860764, Avg Val Acc: 0.6186666670441627 (Best: 0.7161333340406418)\n",
      "=== Epoch: 95 ===\n",
      "Avg Train Loss: 0.8956305158138275, Avg Train Acc: 0.7040487742424011 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.205172422528267, Avg Val Acc: 0.6208000007271767 (Best: 0.7161333340406418)\n",
      "=== Epoch: 96 ===\n",
      "Avg Train Loss: 0.8912331926822662, Avg Train Acc: 0.7043902397155761 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1330383437871934, Avg Val Acc: 0.6009333315491676 (Best: 0.7161333340406418)\n",
      "=== Epoch: 97 ===\n",
      "Avg Train Loss: 0.8960777771472931, Avg Train Acc: 0.7044390207529068 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1617164540290832, Avg Val Acc: 0.6042666679620743 (Best: 0.7161333340406418)\n",
      "=== Epoch: 98 ===\n",
      "Avg Train Loss: 0.8909184491634369, Avg Train Acc: 0.7077073109149933 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.2438993126153945, Avg Val Acc: 0.6094666665792465 (Best: 0.7161333340406418)\n",
      "=== Epoch: 99 ===\n",
      "Avg Train Loss: 0.8885934937000275, Avg Train Acc: 0.7064877986907959 (Best: 0.7161333340406418)\n",
      "Avg Val Loss: 1.1947332978248597, Avg Val Acc: 0.6217333295941353 (Best: 0.7161333340406418)\n"
     ]
    }
   ],
   "source": [
    "if detector.train:\n",
    "    detector.trainModel(train_X=train_X, train_Y = train_y, val_X=val_X, val_Y=val_y, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.6694000005424022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6694000005424022"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.testModel(test_X=test_X, test_Y=test_y)\n",
    "# , modelName=f\"{detector.model_name}_check_point\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning\n",
    "\n",
    "X = test_X\n",
    "y = test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import combinations\n",
    "\n",
    "def run_experiment(X, y, n_experiments=100):\n",
    "    classes = np.unique(y)\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    for _ in range(n_experiments):\n",
    "        # 隨機選擇5個類別\n",
    "        selected_classes = np.random.choice(classes, 5, replace=False)\n",
    "        \n",
    "        train_indices = []\n",
    "        test_indices = []\n",
    "        \n",
    "        for cls in selected_classes:\n",
    "            cls_indices = np.where(y == cls)[0]\n",
    "            train_indices.extend(np.random.choice(cls_indices, 5, replace=False))\n",
    "            test_indices.extend([idx for idx in cls_indices if idx not in train_indices])\n",
    "\n",
    "        X_train, y_train = X[train_indices], y[train_indices]\n",
    "        X_test, y_test = X[test_indices], y[test_indices]\n",
    "\n",
    "        # 訓練SVM\n",
    "        svm = SVC(kernel='rbf', gamma='scale')\n",
    "        svm.fit(X_train, y_train)\n",
    "        \n",
    "        # 預測並計算準確率\n",
    "        y_pred = svm.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    return np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 5-way 5-shot accuracy: 0.7388\n"
     ]
    }
   ],
   "source": [
    "avg_accuracy = run_experiment(X, y)\n",
    "print(f\"Average 5-way 5-shot accuracy: {avg_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byteSequence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
