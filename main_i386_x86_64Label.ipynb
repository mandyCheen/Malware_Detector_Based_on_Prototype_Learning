{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all datasets...\n",
      "train dataset shape: (1420, 14)\n",
      "train dataset family number: 71\n",
      "test dataset shape: (620, 14)\n",
      "test dataset family number: 31\n",
      "val dataset shape: (220, 14)\n",
      "val dataset family number: 11\n",
      "Vectorizing byte sequence using TF-IDF.\n"
     ]
    }
   ],
   "source": [
    "from malwareDetector import malwareDetector\n",
    "from dataLoader import DatasetLoad\n",
    "from byteSequenceVectorize import ByteSequenceVectorizer\n",
    "\n",
    "detector = malwareDetector(cluster=False, train=True, val=True, cpuArch=\"i386_x86_64Label\",\n",
    "                            support_shots=5, query_shots=5, class_per_iter=20, class_per_iter_test=10,\n",
    "                            loss=\"nn_prototypical\", dropout_prob=0.5, splitByCpu=True, dataset=\"diec\")\n",
    "\n",
    "dataset = DatasetLoad(detector)\n",
    "\n",
    "vectorize = ByteSequenceVectorizer(method = \"tfidf\", detector = detector, dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorize Method:  tfidf\n",
      "Loading vectorized byte sequence from ./embedding/diec...\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorize Method: \", vectorize.vectorize_method)\n",
    "featureDim = 1000\n",
    "n_gramRange = (2, 4)\n",
    "\n",
    "train_X, test_X, val_X, train_y, test_y, val_y, train_map, test_map, val_map = vectorize.vectorize_func(featureDim, n_gramRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape:  (1420, 1000) <class 'numpy.ndarray'>\n",
      "Train y shape:  (1420,) <class 'numpy.ndarray'>\n",
      "Test X shape:  (620, 1000)\n",
      "Test y shape:  (620,)\n",
      "Val X shape:  (220, 1000)\n",
      "Val y shape:  (220,)\n",
      "Train Map:  {0: 'adore_Advanced Micro Devices X86-64', 1: 'aenjaris_Advanced Micro Devices X86-64', 2: 'blueshell_Advanced Micro Devices X86-64', 3: 'bpfdoor_Advanced Micro Devices X86-64', 4: 'camelot_Advanced Micro Devices X86-64', 5: 'chisel_Advanced Micro Devices X86-64', 6: 'cleanlog_Advanced Micro Devices X86-64', 7: 'cobaltstrike_Advanced Micro Devices X86-64', 8: 'connectback_Advanced Micro Devices X86-64', 9: 'cryptonote_Advanced Micro Devices X86-64', 10: 'ddosia_Advanced Micro Devices X86-64', 11: 'diamorphine_Advanced Micro Devices X86-64', 12: 'dirtycow_Advanced Micro Devices X86-64', 13: 'dnsamp_Advanced Micro Devices X86-64', 14: 'dnscat_Advanced Micro Devices X86-64', 15: 'dropperl_Advanced Micro Devices X86-64', 16: 'drtycow_Advanced Micro Devices X86-64', 17: 'ebury_Advanced Micro Devices X86-64', 18: 'elfpatch_Advanced Micro Devices X86-64', 19: 'elfpatcher_Advanced Micro Devices X86-64', 20: 'emperor_Advanced Micro Devices X86-64', 21: 'exploitscan_Advanced Micro Devices X86-64', 22: 'ezuriloader_Advanced Micro Devices X86-64', 23: 'fakeapp_Advanced Micro Devices X86-64', 24: 'fakebank_Advanced Micro Devices X86-64', 25: 'fritzfrog_Advanced Micro Devices X86-64', 26: 'fscan_Advanced Micro Devices X86-64', 27: 'gafgyt_Advanced Micro Devices X86-64', 28: 'gost_Advanced Micro Devices X86-64', 29: 'hive_Advanced Micro Devices X86-64', 30: 'horsepill_Advanced Micro Devices X86-64', 31: 'jynx_Advanced Micro Devices X86-64', 32: 'kaiji_Advanced Micro Devices X86-64', 33: 'lady_Advanced Micro Devices X86-64', 34: 'malsource_Advanced Micro Devices X86-64', 35: 'malxmr_Advanced Micro Devices X86-64', 36: 'merlin_Advanced Micro Devices X86-64', 37: 'meterpreter_Advanced Micro Devices X86-64', 38: 'mirai_Advanced Micro Devices X86-64', 39: 'mobidash_Advanced Micro Devices X86-64', 40: 'multiverze_Advanced Micro Devices X86-64', 41: 'pkexecexploit_Advanced Micro Devices X86-64', 42: 'pnscan_Advanced Micro Devices X86-64', 43: 'poseidon_Advanced Micro Devices X86-64', 44: 'prism_Advanced Micro Devices X86-64', 45: 'prochider_Advanced Micro Devices X86-64', 46: 'psybnc_Advanced Micro Devices X86-64', 47: 'pupy_Advanced Micro Devices X86-64', 48: 'rekoobe_Advanced Micro Devices X86-64', 49: 'reptile_Advanced Micro Devices X86-64', 50: 'reversessh_Advanced Micro Devices X86-64', 51: 'revproxy_Advanced Micro Devices X86-64', 52: 'roopre_Advanced Micro Devices X86-64', 53: 'rozena_Advanced Micro Devices X86-64', 54: 'sagnt_Advanced Micro Devices X86-64', 55: 'shelma_Advanced Micro Devices X86-64', 56: 'sickabs_Advanced Micro Devices X86-64', 57: 'skidmap_Advanced Micro Devices X86-64', 58: 'sliver_Advanced Micro Devices X86-64', 59: 'sshdkit_Advanced Micro Devices X86-64', 60: 'sshdoor_Advanced Micro Devices X86-64', 61: 'stowaway_Advanced Micro Devices X86-64', 62: 'sutekh_Advanced Micro Devices X86-64', 63: 'tsunami_Advanced Micro Devices X86-64', 64: 'vtflooder_Advanced Micro Devices X86-64', 65: 'wacatac_Advanced Micro Devices X86-64', 66: 'winexe_Advanced Micro Devices X86-64', 67: 'winnti_Advanced Micro Devices X86-64', 68: 'wroba_Advanced Micro Devices X86-64', 69: 'xmrig_Advanced Micro Devices X86-64', 70: 'xmrminer_Advanced Micro Devices X86-64'}\n",
      "Test Map:  {0: 'asacub_Intel 80386', 1: 'backconn_Intel 80386', 2: 'backegmm_Intel 80386', 3: 'coper_Intel 80386', 4: 'cornelgen_Intel 80386', 5: 'crondum_Intel 80386', 6: 'drtycow_Intel 80386', 7: 'epoll_Intel 80386', 8: 'equationdrug_Intel 80386', 9: 'exploitscan_Intel 80386', 10: 'fakebank_Intel 80386', 11: 'ingopack_Intel 80386', 12: 'kaiji_Intel 80386', 13: 'lardlond_Intel 80386', 14: 'local_Intel 80386', 15: 'meche_Intel 80386', 16: 'meterpreter_Intel 80386', 17: 'mirai_Intel 80386', 18: 'mumblehard_Intel 80386', 19: 'pnscan_Intel 80386', 20: 'prochider_Intel 80386', 21: 'ramen_Intel 80386', 22: 'regon_Intel 80386', 23: 'rkit_Intel 80386', 24: 'sckit_Intel 80386', 25: 'setag_Intel 80386', 26: 'shellshock_Intel 80386', 27: 'sshbrute_Intel 80386', 28: 'tsunami_Intel 80386', 29: 'venom_Intel 80386', 30: 'xorddos_Intel 80386'}\n",
      "Val Map:  {0: 'cleanlog_Intel 80386', 1: 'connectback_Intel 80386', 2: 'dnsamp_Intel 80386', 3: 'gafgyt_Intel 80386', 4: 'matrics_Intel 80386', 5: 'mobidash_Intel 80386', 6: 'nuker_Intel 80386', 7: 'race_Intel 80386', 8: 'sliver_Intel 80386', 9: 'sshdoor_Intel 80386', 10: 'wroba_Intel 80386'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train X shape: \", train_X.shape, type(train_X))\n",
    "print(\"Train y shape: \", train_y.shape, type(train_y))\n",
    "print(\"Test X shape: \", test_X.shape)\n",
    "print(\"Test y shape: \", test_y.shape)\n",
    "if(val_X is not None):\n",
    "    print(\"Val X shape: \", val_X.shape)\n",
    "    print(\"Val y shape: \", val_y.shape)\n",
    "print(\"Train Map: \", train_map)\n",
    "print(\"Test Map: \", test_map)\n",
    "if(val_map is not None):\n",
    "    print(\"Val Map: \", val_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes per iteration: 20\n",
      "N-shot: 5\n",
      "=== Epoch: 0 ===\n",
      "Avg Train Loss: 2.7838215899467467, Avg Train Acc: 0.15770000115036964 (Best)\n",
      "Avg Val Loss: 1.609046128988266, Avg Val Acc: 0.7423333323001862 (Best)\n",
      "Model saved at ./model/diec/model_i386_x86_64Label_nn_prototypical_splitByCpu_withVal.pt\n",
      "=== Epoch: 1 ===\n",
      "Avg Train Loss: 2.2949574995040893, Avg Train Acc: 0.22339999973773955 (Best: 0.7423333323001862)\n",
      "Avg Val Loss: 1.5314428806304932, Avg Val Acc: 0.7441333317756653 (Best)\n",
      "Model saved at ./model/diec/model_i386_x86_64Label_nn_prototypical_splitByCpu_withVal.pt\n",
      "=== Epoch: 2 ===\n",
      "Avg Train Loss: 2.043935271501541, Avg Train Acc: 0.27640000194311143 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.4243928980827332, Avg Val Acc: 0.7132000017166138 (Best: 0.7441333317756653)\n",
      "=== Epoch: 3 ===\n",
      "Avg Train Loss: 1.9314116895198823, Avg Train Acc: 0.3033000016212463 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.3770124220848083, Avg Val Acc: 0.7139999973773956 (Best: 0.7441333317756653)\n",
      "=== Epoch: 4 ===\n",
      "Avg Train Loss: 1.80512913107872, Avg Train Acc: 0.33570000022649765 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.3466579627990722, Avg Val Acc: 0.725 (Best: 0.7441333317756653)\n",
      "=== Epoch: 5 ===\n",
      "Avg Train Loss: 1.697585483789444, Avg Train Acc: 0.3678000000119209 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.2947632801532745, Avg Val Acc: 0.7128666681051254 (Best: 0.7441333317756653)\n",
      "=== Epoch: 6 ===\n",
      "Avg Train Loss: 1.6280780148506164, Avg Train Acc: 0.388199999332428 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.2806648230552673, Avg Val Acc: 0.718733332157135 (Best: 0.7441333317756653)\n",
      "=== Epoch: 7 ===\n",
      "Avg Train Loss: 1.5940761721134187, Avg Train Acc: 0.3966999998688698 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.3110767674446107, Avg Val Acc: 0.7003333342075347 (Best: 0.7441333317756653)\n",
      "=== Epoch: 8 ===\n",
      "Avg Train Loss: 1.5475979936122894, Avg Train Acc: 0.4101999962329865 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.2973828148841857, Avg Val Acc: 0.7112000006437301 (Best: 0.7441333317756653)\n",
      "=== Epoch: 9 ===\n",
      "Avg Train Loss: 1.4939803862571717, Avg Train Acc: 0.4351999959349632 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.3140590190887451, Avg Val Acc: 0.7094666683673858 (Best: 0.7441333317756653)\n",
      "=== Epoch: 10 ===\n",
      "Avg Train Loss: 1.4478639924526215, Avg Train Acc: 0.4595999982953072 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.2699804258346559, Avg Val Acc: 0.7094666683673858 (Best: 0.7441333317756653)\n",
      "=== Epoch: 11 ===\n",
      "Avg Train Loss: 1.4562012434005738, Avg Train Acc: 0.45059999734163286 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.2114477932453156, Avg Val Acc: 0.7124666661024094 (Best: 0.7441333317756653)\n",
      "=== Epoch: 12 ===\n",
      "Avg Train Loss: 1.3917677438259124, Avg Train Acc: 0.46899999588727953 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1822590148448944, Avg Val Acc: 0.730133330821991 (Best: 0.7441333317756653)\n",
      "=== Epoch: 13 ===\n",
      "Avg Train Loss: 1.388556605577469, Avg Train Acc: 0.47659999758005145 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1806602048873902, Avg Val Acc: 0.7229333335161209 (Best: 0.7441333317756653)\n",
      "=== Epoch: 14 ===\n",
      "Avg Train Loss: 1.353931746482849, Avg Train Acc: 0.47749999791383746 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1721992325782775, Avg Val Acc: 0.7188666659593582 (Best: 0.7441333317756653)\n",
      "=== Epoch: 15 ===\n",
      "Avg Train Loss: 1.3423224651813508, Avg Train Acc: 0.47839999824762347 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1793333625793456, Avg Val Acc: 0.6957333356142044 (Best: 0.7441333317756653)\n",
      "=== Epoch: 16 ===\n",
      "Avg Train Loss: 1.3389401614665986, Avg Train Acc: 0.49239999502897264 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.2127888774871827, Avg Val Acc: 0.7001999962329865 (Best: 0.7441333317756653)\n",
      "=== Epoch: 17 ===\n",
      "Avg Train Loss: 1.3158850586414337, Avg Train Acc: 0.49319999665021896 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.2163572549819945, Avg Val Acc: 0.7206000006198883 (Best: 0.7441333317756653)\n",
      "=== Epoch: 18 ===\n",
      "Avg Train Loss: 1.2589092630147933, Avg Train Acc: 0.5168999978899955 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1917360150814056, Avg Val Acc: 0.6979999989271164 (Best: 0.7441333317756653)\n",
      "=== Epoch: 19 ===\n",
      "Avg Train Loss: 1.2990463215112686, Avg Train Acc: 0.5063999974727631 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.124306093454361, Avg Val Acc: 0.7254666674137116 (Best: 0.7441333317756653)\n",
      "=== Epoch: 20 ===\n",
      "Avg Train Loss: 1.268609298467636, Avg Train Acc: 0.5188999956846237 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1528255248069763, Avg Val Acc: 0.7376666688919067 (Best: 0.7441333317756653)\n",
      "=== Epoch: 21 ===\n",
      "Avg Train Loss: 1.2582980239391326, Avg Train Acc: 0.515799997150898 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.139395630955696, Avg Val Acc: 0.7232666671276092 (Best: 0.7441333317756653)\n",
      "=== Epoch: 22 ===\n",
      "Avg Train Loss: 1.1857941734790802, Avg Train Acc: 0.5394999974966049 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1283351135253907, Avg Val Acc: 0.7367999976873398 (Best: 0.7441333317756653)\n",
      "=== Epoch: 23 ===\n",
      "Avg Train Loss: 1.1801657634973526, Avg Train Acc: 0.5396999984979629 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.146420767903328, Avg Val Acc: 0.7381999987363815 (Best: 0.7441333317756653)\n",
      "=== Epoch: 24 ===\n",
      "Avg Train Loss: 1.1806465131044388, Avg Train Acc: 0.5465999963879585 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0985035568475723, Avg Val Acc: 0.7282666665315628 (Best: 0.7441333317756653)\n",
      "=== Epoch: 25 ===\n",
      "Avg Train Loss: 1.1651247411966323, Avg Train Acc: 0.5555999967455864 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1084838873147964, Avg Val Acc: 0.7185333329439163 (Best: 0.7441333317756653)\n",
      "=== Epoch: 26 ===\n",
      "Avg Train Loss: 1.1725857013463974, Avg Train Acc: 0.5508999988436699 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1061511468887328, Avg Val Acc: 0.7138666671514511 (Best: 0.7441333317756653)\n",
      "=== Epoch: 27 ===\n",
      "Avg Train Loss: 1.1506139016151429, Avg Train Acc: 0.558699999153614 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0925285524129869, Avg Val Acc: 0.7293333315849304 (Best: 0.7441333317756653)\n",
      "=== Epoch: 28 ===\n",
      "Avg Train Loss: 1.1617759132385255, Avg Train Acc: 0.5551999971270561 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.126893453001976, Avg Val Acc: 0.7184666663408279 (Best: 0.7441333317756653)\n",
      "=== Epoch: 29 ===\n",
      "Avg Train Loss: 1.140266335606575, Avg Train Acc: 0.5591999962925911 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1155906093120576, Avg Val Acc: 0.7125333321094512 (Best: 0.7441333317756653)\n",
      "=== Epoch: 30 ===\n",
      "Avg Train Loss: 1.1594256019592286, Avg Train Acc: 0.5572999969124794 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1483440619707108, Avg Val Acc: 0.709266664981842 (Best: 0.7441333317756653)\n",
      "=== Epoch: 31 ===\n",
      "Avg Train Loss: 1.1420656251907348, Avg Train Acc: 0.5543000012636184 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1125957369804382, Avg Val Acc: 0.7278000009059906 (Best: 0.7441333317756653)\n",
      "=== Epoch: 32 ===\n",
      "Avg Train Loss: 1.1172055220603943, Avg Train Acc: 0.5681000012159347 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1122037237882614, Avg Val Acc: 0.7024000036716461 (Best: 0.7441333317756653)\n",
      "=== Epoch: 33 ===\n",
      "Avg Train Loss: 1.1206685543060302, Avg Train Acc: 0.5672999992966652 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0686640018224716, Avg Val Acc: 0.7102666699886322 (Best: 0.7441333317756653)\n",
      "=== Epoch: 34 ===\n",
      "Avg Train Loss: 1.1312322586774826, Avg Train Acc: 0.5656999999284744 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0523827695846557, Avg Val Acc: 0.7210666650533676 (Best: 0.7441333317756653)\n",
      "=== Epoch: 35 ===\n",
      "Avg Train Loss: 1.126781309247017, Avg Train Acc: 0.5679999971389771 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0636076736450195, Avg Val Acc: 0.7271333307027816 (Best: 0.7441333317756653)\n",
      "=== Epoch: 36 ===\n",
      "Avg Train Loss: 1.1441999793052673, Avg Train Acc: 0.5546999987959862 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0427787989377975, Avg Val Acc: 0.7309333324432373 (Best: 0.7441333317756653)\n",
      "=== Epoch: 37 ===\n",
      "Avg Train Loss: 1.1109087294340134, Avg Train Acc: 0.575199998319149 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1137235659360885, Avg Val Acc: 0.7316000020503998 (Best: 0.7441333317756653)\n",
      "=== Epoch: 38 ===\n",
      "Avg Train Loss: 1.0987333446741103, Avg Train Acc: 0.5770999959111214 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0727586460113525, Avg Val Acc: 0.7249333333969116 (Best: 0.7441333317756653)\n",
      "=== Epoch: 39 ===\n",
      "Avg Train Loss: 1.1270044666528702, Avg Train Acc: 0.5691999980807304 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0966343611478806, Avg Val Acc: 0.717333334684372 (Best: 0.7441333317756653)\n",
      "=== Epoch: 40 ===\n",
      "Avg Train Loss: 1.103953731060028, Avg Train Acc: 0.5763999965786933 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0832983028888703, Avg Val Acc: 0.7201999962329865 (Best: 0.7441333317756653)\n",
      "=== Epoch: 41 ===\n",
      "Avg Train Loss: 1.1016317695379256, Avg Train Acc: 0.5795000013709068 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.078498311638832, Avg Val Acc: 0.7214666682481766 (Best: 0.7441333317756653)\n",
      "=== Epoch: 42 ===\n",
      "Avg Train Loss: 1.081584525704384, Avg Train Acc: 0.5884999996423721 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1032200098037719, Avg Val Acc: 0.7257333332300187 (Best: 0.7441333317756653)\n",
      "=== Epoch: 43 ===\n",
      "Avg Train Loss: 1.0996548920869826, Avg Train Acc: 0.5804999995231629 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0630086416006088, Avg Val Acc: 0.7298000001907349 (Best: 0.7441333317756653)\n",
      "=== Epoch: 44 ===\n",
      "Avg Train Loss: 1.0526234805583954, Avg Train Acc: 0.5933999982476235 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0597077840566635, Avg Val Acc: 0.7328000020980835 (Best: 0.7441333317756653)\n",
      "=== Epoch: 45 ===\n",
      "Avg Train Loss: 1.039796483516693, Avg Train Acc: 0.6025999975204468 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0650825315713883, Avg Val Acc: 0.7236666685342789 (Best: 0.7441333317756653)\n",
      "=== Epoch: 46 ===\n",
      "Avg Train Loss: 1.0573582792282104, Avg Train Acc: 0.588999997973442 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.059295778274536, Avg Val Acc: 0.7264666664600372 (Best: 0.7441333317756653)\n",
      "=== Epoch: 47 ===\n",
      "Avg Train Loss: 1.0860738748311995, Avg Train Acc: 0.5779999980330467 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0590620052814483, Avg Val Acc: 0.7240666675567627 (Best: 0.7441333317756653)\n",
      "=== Epoch: 48 ===\n",
      "Avg Train Loss: 1.0637136119604111, Avg Train Acc: 0.600600001513958 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0817621737718581, Avg Val Acc: 0.7158666694164276 (Best: 0.7441333317756653)\n",
      "=== Epoch: 49 ===\n",
      "Avg Train Loss: 1.0763180392980576, Avg Train Acc: 0.5917999991774558 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0628033190965653, Avg Val Acc: 0.7237333327531814 (Best: 0.7441333317756653)\n",
      "=== Epoch: 50 ===\n",
      "Avg Train Loss: 1.0650239104032517, Avg Train Acc: 0.5809999966621399 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0531526631116868, Avg Val Acc: 0.7316666680574417 (Best: 0.7441333317756653)\n",
      "=== Epoch: 51 ===\n",
      "Avg Train Loss: 1.0553691190481187, Avg Train Acc: 0.5982000002264977 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0303542667627335, Avg Val Acc: 0.7310666680335999 (Best: 0.7441333317756653)\n",
      "=== Epoch: 52 ===\n",
      "Avg Train Loss: 1.036910302042961, Avg Train Acc: 0.6104999986290932 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.087865206003189, Avg Val Acc: 0.7145999997854233 (Best: 0.7441333317756653)\n",
      "=== Epoch: 53 ===\n",
      "Avg Train Loss: 1.0468081057071685, Avg Train Acc: 0.5962999972701073 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1056519412994386, Avg Val Acc: 0.7346666669845581 (Best: 0.7441333317756653)\n",
      "=== Epoch: 54 ===\n",
      "Avg Train Loss: 1.0341515070199967, Avg Train Acc: 0.5991999977827072 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0367161989212037, Avg Val Acc: 0.7369999986886978 (Best: 0.7441333317756653)\n",
      "=== Epoch: 55 ===\n",
      "Avg Train Loss: 1.024456749558449, Avg Train Acc: 0.6007999983429909 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0761817568540573, Avg Val Acc: 0.725466668009758 (Best: 0.7441333317756653)\n",
      "=== Epoch: 56 ===\n",
      "Avg Train Loss: 1.0708569687604905, Avg Train Acc: 0.5916999992728234 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0766182553768158, Avg Val Acc: 0.7358000010251999 (Best: 0.7441333317756653)\n",
      "=== Epoch: 57 ===\n",
      "Avg Train Loss: 1.015775228738785, Avg Train Acc: 0.603899998664856 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0800099486112595, Avg Val Acc: 0.7171333318948746 (Best: 0.7441333317756653)\n",
      "=== Epoch: 58 ===\n",
      "Avg Train Loss: 1.0183661806583404, Avg Train Acc: 0.603499998152256 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0870075345039367, Avg Val Acc: 0.7160000014305115 (Best: 0.7441333317756653)\n",
      "=== Epoch: 59 ===\n",
      "Avg Train Loss: 1.0155951714515685, Avg Train Acc: 0.601800000667572 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.076662886738777, Avg Val Acc: 0.7402666676044464 (Best: 0.7441333317756653)\n",
      "=== Epoch: 60 ===\n",
      "Avg Train Loss: 1.033589807152748, Avg Train Acc: 0.598799998164177 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0908380138874054, Avg Val Acc: 0.720866664648056 (Best: 0.7441333317756653)\n",
      "=== Epoch: 61 ===\n",
      "Avg Train Loss: 1.0193574357032775, Avg Train Acc: 0.6143000000715255 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0940327721834182, Avg Val Acc: 0.7070666664838791 (Best: 0.7441333317756653)\n",
      "=== Epoch: 62 ===\n",
      "Avg Train Loss: 1.0116337651014329, Avg Train Acc: 0.6096999996900558 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0887578749656677, Avg Val Acc: 0.7370000034570694 (Best: 0.7441333317756653)\n",
      "=== Epoch: 63 ===\n",
      "Avg Train Loss: 1.0223375886678696, Avg Train Acc: 0.6072000014781952 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0613691425323486, Avg Val Acc: 0.7259333336353302 (Best: 0.7441333317756653)\n",
      "=== Epoch: 64 ===\n",
      "Avg Train Loss: 0.9981172168254853, Avg Train Acc: 0.6092000004649162 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0501695293188096, Avg Val Acc: 0.7286000007390976 (Best: 0.7441333317756653)\n",
      "=== Epoch: 65 ===\n",
      "Avg Train Loss: 1.0351881718635558, Avg Train Acc: 0.6087000000476838 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0502229982614517, Avg Val Acc: 0.7343999987840653 (Best: 0.7441333317756653)\n",
      "=== Epoch: 66 ===\n",
      "Avg Train Loss: 1.0392264252901078, Avg Train Acc: 0.6000000035762787 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0689975309371949, Avg Val Acc: 0.7303333342075348 (Best: 0.7441333317756653)\n",
      "=== Epoch: 67 ===\n",
      "Avg Train Loss: 0.9929728102684021, Avg Train Acc: 0.6146999996900558 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0737666779756545, Avg Val Acc: 0.7263333326578141 (Best: 0.7441333317756653)\n",
      "=== Epoch: 68 ===\n",
      "Avg Train Loss: 0.9835266840457916, Avg Train Acc: 0.6186999991536141 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0703700226545334, Avg Val Acc: 0.7249333322048187 (Best: 0.7441333317756653)\n",
      "=== Epoch: 69 ===\n",
      "Avg Train Loss: 1.0378717017173766, Avg Train Acc: 0.6041999995708466 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0883779400587081, Avg Val Acc: 0.7190666681528092 (Best: 0.7441333317756653)\n",
      "=== Epoch: 70 ===\n",
      "Avg Train Loss: 1.014326543211937, Avg Train Acc: 0.6156999984383583 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0836440634727478, Avg Val Acc: 0.7249999982118607 (Best: 0.7441333317756653)\n",
      "=== Epoch: 71 ===\n",
      "Avg Train Loss: 1.032438280582428, Avg Train Acc: 0.6055999994277954 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1015753382444382, Avg Val Acc: 0.7300000005960464 (Best: 0.7441333317756653)\n",
      "=== Epoch: 72 ===\n",
      "Avg Train Loss: 1.0051234781742096, Avg Train Acc: 0.618499999344349 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0925143128633499, Avg Val Acc: 0.7184666693210602 (Best: 0.7441333317756653)\n",
      "=== Epoch: 73 ===\n",
      "Avg Train Loss: 1.01746686398983, Avg Train Acc: 0.6082000008225441 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.068881130218506, Avg Val Acc: 0.7213333368301391 (Best: 0.7441333317756653)\n",
      "=== Epoch: 74 ===\n",
      "Avg Train Loss: 1.00488354742527, Avg Train Acc: 0.616499999165535 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0811518782377243, Avg Val Acc: 0.722333333492279 (Best: 0.7441333317756653)\n",
      "=== Epoch: 75 ===\n",
      "Avg Train Loss: 1.013569164276123, Avg Train Acc: 0.6045999974012375 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.077107720375061, Avg Val Acc: 0.725533332824707 (Best: 0.7441333317756653)\n",
      "=== Epoch: 76 ===\n",
      "Avg Train Loss: 0.9629284012317657, Avg Train Acc: 0.6287999999523163 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0734619098901748, Avg Val Acc: 0.7320000010728837 (Best: 0.7441333317756653)\n",
      "=== Epoch: 77 ===\n",
      "Avg Train Loss: 0.9871172040700913, Avg Train Acc: 0.6216000017523765 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0355221021175385, Avg Val Acc: 0.7149999976158142 (Best: 0.7441333317756653)\n",
      "=== Epoch: 78 ===\n",
      "Avg Train Loss: 1.0162119573354722, Avg Train Acc: 0.6110999992489815 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0797606766223908, Avg Val Acc: 0.7325333297252655 (Best: 0.7441333317756653)\n",
      "=== Epoch: 79 ===\n",
      "Avg Train Loss: 1.010234733223915, Avg Train Acc: 0.6145000007748603 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0716555047035217, Avg Val Acc: 0.7207999992370605 (Best: 0.7441333317756653)\n",
      "=== Epoch: 80 ===\n",
      "Avg Train Loss: 1.0137398326396942, Avg Train Acc: 0.6076999968290329 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.045241670012474, Avg Val Acc: 0.7271999996900559 (Best: 0.7441333317756653)\n",
      "=== Epoch: 81 ===\n",
      "Avg Train Loss: 0.9878508305549621, Avg Train Acc: 0.6212000027298927 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0548218035697936, Avg Val Acc: 0.7309333342313766 (Best: 0.7441333317756653)\n",
      "=== Epoch: 82 ===\n",
      "Avg Train Loss: 0.9940809088945389, Avg Train Acc: 0.6166999995708465 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0858841854333878, Avg Val Acc: 0.7180000025033951 (Best: 0.7441333317756653)\n",
      "=== Epoch: 83 ===\n",
      "Avg Train Loss: 1.0315932923555373, Avg Train Acc: 0.6114999979734421 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0645129585266113, Avg Val Acc: 0.7289333325624466 (Best: 0.7441333317756653)\n",
      "=== Epoch: 84 ===\n",
      "Avg Train Loss: 0.9851633030176162, Avg Train Acc: 0.6277000007033348 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0721598821878433, Avg Val Acc: 0.7074000006914138 (Best: 0.7441333317756653)\n",
      "=== Epoch: 85 ===\n",
      "Avg Train Loss: 0.9522967737913132, Avg Train Acc: 0.6289999994635582 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.1020802408456802, Avg Val Acc: 0.7105999994277954 (Best: 0.7441333317756653)\n",
      "=== Epoch: 86 ===\n",
      "Avg Train Loss: 1.0057012230157851, Avg Train Acc: 0.616199999153614 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0554673719406127, Avg Val Acc: 0.7139333301782608 (Best: 0.7441333317756653)\n",
      "=== Epoch: 87 ===\n",
      "Avg Train Loss: 0.9911255210638046, Avg Train Acc: 0.6299000000953674 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0958408164978026, Avg Val Acc: 0.7127999979257583 (Best: 0.7441333317756653)\n",
      "=== Epoch: 88 ===\n",
      "Avg Train Loss: 1.0150463616847991, Avg Train Acc: 0.6091999959945679 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0646082276105882, Avg Val Acc: 0.7107999986410141 (Best: 0.7441333317756653)\n",
      "=== Epoch: 89 ===\n",
      "Avg Train Loss: 0.9872885632514954, Avg Train Acc: 0.6248999989032745 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0879308152198792, Avg Val Acc: 0.704866663813591 (Best: 0.7441333317756653)\n",
      "=== Epoch: 90 ===\n",
      "Avg Train Loss: 0.9738392865657807, Avg Train Acc: 0.6296999967098236 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0675527936220168, Avg Val Acc: 0.7139333343505859 (Best: 0.7441333317756653)\n",
      "=== Epoch: 91 ===\n",
      "Avg Train Loss: 1.006423117518425, Avg Train Acc: 0.6145000001788139 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0604859811067582, Avg Val Acc: 0.7129333353042603 (Best: 0.7441333317756653)\n",
      "=== Epoch: 92 ===\n",
      "Avg Train Loss: 0.9926996952295304, Avg Train Acc: 0.624400001168251 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0833978182077408, Avg Val Acc: 0.7082666671276092 (Best: 0.7441333317756653)\n",
      "=== Epoch: 93 ===\n",
      "Avg Train Loss: 0.9704290264844895, Avg Train Acc: 0.6284999984502793 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0695697999000549, Avg Val Acc: 0.7205333334207534 (Best: 0.7441333317756653)\n",
      "=== Epoch: 94 ===\n",
      "Avg Train Loss: 0.9829197686910629, Avg Train Acc: 0.6158000001311302 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0603516179323196, Avg Val Acc: 0.7162000024318695 (Best: 0.7441333317756653)\n",
      "=== Epoch: 95 ===\n",
      "Avg Train Loss: 0.9896849602460861, Avg Train Acc: 0.6223000001907348 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0899136334657669, Avg Val Acc: 0.7196666651964188 (Best: 0.7441333317756653)\n",
      "=== Epoch: 96 ===\n",
      "Avg Train Loss: 0.9419850766658783, Avg Train Acc: 0.6407000014185905 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0802679151296615, Avg Val Acc: 0.7188666665554047 (Best: 0.7441333317756653)\n",
      "=== Epoch: 97 ===\n",
      "Avg Train Loss: 1.0109712141752243, Avg Train Acc: 0.6157999980449677 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0913713401556016, Avg Val Acc: 0.7153333330154419 (Best: 0.7441333317756653)\n",
      "=== Epoch: 98 ===\n",
      "Avg Train Loss: 0.967914006114006, Avg Train Acc: 0.6271999987959862 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.0642656844854355, Avg Val Acc: 0.7317333352565766 (Best: 0.7441333317756653)\n",
      "=== Epoch: 99 ===\n",
      "Avg Train Loss: 0.9934520500898362, Avg Train Acc: 0.6188000002503395 (Best: 0.7441333317756653)\n",
      "Avg Val Loss: 1.069438700079918, Avg Val Acc: 0.7198666685819626 (Best: 0.7441333317756653)\n"
     ]
    }
   ],
   "source": [
    "if detector.train:\n",
    "    detector.trainModel(train_X=train_X, train_Y = train_y, val_X=val_X, val_Y=val_y, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Model: 10-ways 5-shots\n",
      "Load model from ./model/diec/model_i386_x86_64Label_nn_prototypical_splitByCpu_withVal.pt\n",
      "Test Acc: 0.7244066663682461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7244066663682461"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Testing Model: {detector.class_per_iter_test}-ways {detector.support_shots_test}-shots\")\n",
    "detector.testModel(test_X=test_X, test_Y=test_y)\n",
    "# , modelName=f\"{detector.model_name}_check_point\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning\n",
    "\n",
    "X = test_X\n",
    "y = test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import combinations\n",
    "\n",
    "def run_experiment_SVM(X, y, n_experiments=100, n_ways=5, k_shots=5):\n",
    "    classes = np.unique(y)\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    for _ in range(n_experiments):\n",
    "        # 隨機選擇5個類別\n",
    "        selected_classes = np.random.choice(classes, n_ways, replace=False)\n",
    "        \n",
    "        train_indices = []\n",
    "        test_indices = []\n",
    "        \n",
    "        for cls in selected_classes:\n",
    "            cls_indices = np.where(y == cls)[0]\n",
    "            train_indices.extend(np.random.choice(cls_indices, k_shots, replace=False))\n",
    "            test_indices.extend([idx for idx in cls_indices if idx not in train_indices])\n",
    "\n",
    "        X_train, y_train = X[train_indices], y[train_indices]\n",
    "        X_test, y_test = X[test_indices], y[test_indices]\n",
    "\n",
    "        # 訓練SVM\n",
    "        svm = SVC(kernel='rbf', gamma='scale')\n",
    "        svm.fit(X_train, y_train)\n",
    "        \n",
    "        # 預測並計算準確率\n",
    "        y_pred = svm.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    return np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def run_experiment_KNN(X, y, n_experiments=100, n_ways=5, k_shots=5):\n",
    "    classes = np.unique(y)\n",
    "    \n",
    "    accuracies = []\n",
    "    for _ in range(n_experiments):\n",
    "        # 隨機選擇5個類別\n",
    "        selected_classes = np.random.choice(classes, n_ways, replace=False)\n",
    "        \n",
    "        train_indices = []\n",
    "        test_indices = []\n",
    "        \n",
    "        for cls in selected_classes:\n",
    "            cls_indices = np.where(y == cls)[0]\n",
    "            train_indices.extend(np.random.choice(cls_indices, k_shots, replace=False))\n",
    "            test_indices.extend([idx for idx in cls_indices if idx not in train_indices])\n",
    "\n",
    "        X_train, y_train = X[train_indices], y[train_indices]\n",
    "        X_test, y_test = X[test_indices], y[test_indices]\n",
    "\n",
    "        # 訓練KNN\n",
    "        knn = KNeighborsClassifier(n_neighbors=3)\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        # 預測並計算準確率\n",
    "        y_pred = knn.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    \n",
    "    return np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 5-way 5-shot accuracy: 0.7791\n",
      "Average 10-way 5-shot accuracy: 0.6875\n"
     ]
    }
   ],
   "source": [
    "avg_accuracy = run_experiment_SVM(X, y, n_ways=5, k_shots=5)\n",
    "print(f\"Average 5-way 5-shot accuracy: {avg_accuracy:.4f}\")\n",
    "avg_accuracy = run_experiment_SVM(X, y, n_ways=10, k_shots=5)\n",
    "print(f\"Average 10-way 5-shot accuracy: {avg_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 5-way 5-shot accuracy: 0.7451\n",
      "Average 10-way 5-shot accuracy: 0.6980\n"
     ]
    }
   ],
   "source": [
    "avg_accuracy = run_experiment_KNN(X, y, n_ways=5, k_shots=5)\n",
    "print(f\"Average 5-way 5-shot accuracy: {avg_accuracy:.4f}\")\n",
    "avg_accuracy = run_experiment_KNN(X, y, n_ways=10, k_shots=5)\n",
    "print(f\"Average 10-way 5-shot accuracy: {avg_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byteSequence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
